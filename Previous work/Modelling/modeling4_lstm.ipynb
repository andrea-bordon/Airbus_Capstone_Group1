{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_simulated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'UTC_TIME' column to datetime format and sort by time\n",
    "df['UTC_TIME'] = pd.to_datetime(df['UTC_TIME'])\n",
    "df.sort_values(by=['FLIGHT_INSTANCE', 'UTC_TIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelvant columns\n",
    "df = df.drop(columns=['FLIGHT_PHASE_COUNT', 'Flight','MSN', 'FLIGHT_INSTANCE', 'NEW_FLIGHT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 376554 entries, 0 to 337922\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   UTC_TIME                   376554 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                376554 non-null  float64       \n",
      " 2   FUEL_USED_3                376554 non-null  float64       \n",
      " 3   FUEL_USED_4                376554 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            376554 non-null  float64       \n",
      " 5   VALUE_FOB                  376554 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          376554 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         376554 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         376554 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         376554 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         376554 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         376554 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         376554 non-null  float64       \n",
      " 13  FUEL_USED_1                376554 non-null  float64       \n",
      " 14  FLIGHT_ID                  376554 non-null  object        \n",
      " 15  START_FOB                  376554 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            376554 non-null  float64       \n",
      " 17  EXPECTED_FOB               376554 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             376554 non-null  float64       \n",
      " 19  FOB_CHANGE                 376554 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        376554 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             376554 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              376554 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              376554 non-null  float64       \n",
      " 24  LW_RW_DIFF                 376554 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              376554 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        376554 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  376554 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              376554 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             376554 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 89.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    343079\n",
       "1     33475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LEAK_FLOW_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting out all No-Leak Flights before 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify flights with leaks (Keep these)\n",
    "leak_flights = df[df[\"LEAK_FLOW_FLAG\"] == 1][\"FLIGHT_ID\"].unique()\n",
    "\n",
    "# Identify no-leak flights that started before 2017\n",
    "no_leak_flights = df[df[\"LEAK_FLOW_FLAG\"] == 0].groupby(\"FLIGHT_ID\")[\"UTC_TIME\"].min()\n",
    "no_leak_flights_to_remove = no_leak_flights[no_leak_flights < \"2017-10-22\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Keep all leak flights + no-leak flights that started in 2017 or later\n",
    "df_filtered = df[df[\"FLIGHT_ID\"].isin(leak_flights) | ~df[\"FLIGHT_ID\"].isin(no_leak_flights_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 376554\n",
      "Filtered dataset size: 247584\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataset size: {df.shape[0]}\")\n",
    "print(f\"Filtered dataset size: {df_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    214109\n",
       "1     33475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['LEAK_FLOW_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median Number of Leaks per Flight: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Get mean of leaks per flight (better than sum bc each flight may have varying flight durations)\n",
    "flight_leak_counts = df_filtered.groupby(\"FLIGHT_ID\")[\"LEAK_FLOW_FLAG\"].mean()\n",
    "\n",
    "# Compute the media Number of Leaks per Flight\n",
    "median_leaks_per_flight = flight_leak_counts[flight_leak_counts > 0].median()\n",
    "print(f\"median Number of Leaks per Flight: {median_leaks_per_flight:.2f}\")\n",
    "\n",
    "# Select flights where the number of leaks is higher than the median\n",
    "flights_with_leaks = flight_leak_counts[flight_leak_counts > median_leaks_per_flight].index\n",
    "\n",
    "# EXTREME Reduction: Only keep 80% as many no-leak flights as leak flights\n",
    "num_leak_flights = len(flights_with_leaks)  # Total number of flights with leaks\n",
    "num_no_leak_flights = int(num_leak_flights * 0.80)  # Cut down no-leak flights \n",
    "\n",
    "# Sample only the reduced number of no-leak flights\n",
    "flights_no_leaks = flight_leak_counts[flight_leak_counts == 0].sample(\n",
    "    n=num_no_leak_flights, \n",
    "    random_state=42\n",
    ").index\n",
    "\n",
    "# Keep only selected flights (Preserves sequences!)\n",
    "df_balanced = df_filtered[df_filtered[\"FLIGHT_ID\"].isin(flights_with_leaks.union(flights_no_leaks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    76.336882\n",
       "1    23.663118\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced[\"LEAK_FLOW_FLAG\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106423 entries, 153 to 337922\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   UTC_TIME                   106423 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                106423 non-null  float64       \n",
      " 2   FUEL_USED_3                106423 non-null  float64       \n",
      " 3   FUEL_USED_4                106423 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            106423 non-null  float64       \n",
      " 5   VALUE_FOB                  106423 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          106423 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         106423 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         106423 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         106423 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         106423 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         106423 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         106423 non-null  float64       \n",
      " 13  FUEL_USED_1                106423 non-null  float64       \n",
      " 14  FLIGHT_ID                  106423 non-null  object        \n",
      " 15  START_FOB                  106423 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            106423 non-null  float64       \n",
      " 17  EXPECTED_FOB               106423 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             106423 non-null  float64       \n",
      " 19  FOB_CHANGE                 106423 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        106423 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             106423 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              106423 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              106423 non-null  float64       \n",
      " 24  LW_RW_DIFF                 106423 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              106423 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        106423 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  106423 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              106423 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             106423 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all features (except the target)\n",
    "features = df_balanced.columns.tolist()\n",
    "features.remove('LEAK_FLOW_FLAG')  # Remove target column from features\n",
    "\n",
    "# Target variable\n",
    "target = 'LEAK_FLOW_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values (due to lagging)\n",
    "df_balanced.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106423 entries, 153 to 337922\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   UTC_TIME                   106423 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                106423 non-null  float64       \n",
      " 2   FUEL_USED_3                106423 non-null  float64       \n",
      " 3   FUEL_USED_4                106423 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            106423 non-null  float64       \n",
      " 5   VALUE_FOB                  106423 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          106423 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         106423 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         106423 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         106423 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         106423 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         106423 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         106423 non-null  float64       \n",
      " 13  FUEL_USED_1                106423 non-null  float64       \n",
      " 14  FLIGHT_ID                  106423 non-null  object        \n",
      " 15  START_FOB                  106423 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            106423 non-null  float64       \n",
      " 17  EXPECTED_FOB               106423 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             106423 non-null  float64       \n",
      " 19  FOB_CHANGE                 106423 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        106423 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             106423 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              106423 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              106423 non-null  float64       \n",
      " 24  LW_RW_DIFF                 106423 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              106423 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        106423 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  106423 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              106423 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             106423 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_balanced.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort flights by first recorded timestamp\n",
    "flight_start_times = df_balanced.groupby(\"FLIGHT_ID\")[\"UTC_TIME\"].min().sort_values()\n",
    "\n",
    "# Step 2: Define the split point (80% train, 20% test)\n",
    "split_index = int(len(flight_start_times) * 0.8)  # Get the 80% split point\n",
    "\n",
    "# Step 3: Assign the first 80% of flights to training, last 20% to testing\n",
    "train_flights = flight_start_times.index[:split_index]  # First 80% of flights\n",
    "test_flights = flight_start_times.index[split_index:]  # Last 20% of flights\n",
    "\n",
    "train_df = df_balanced[df_balanced[\"FLIGHT_ID\"].isin(train_flights)]\n",
    "test_df = df_balanced[df_balanced[\"FLIGHT_ID\"].isin(test_flights)]\n",
    "\n",
    "# Step 4: Reset index \n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features & target\n",
    "features = [col for col in train_df.columns if col not in ['FLIGHT_ID', 'UTC_TIME', 'LEAK_FLOW_FLAG']]\n",
    "target = \"LEAK_FLOW_FLAG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75861 entries, 0 to 75860\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   UTC_TIME                   75861 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                75861 non-null  float64       \n",
      " 2   FUEL_USED_3                75861 non-null  float64       \n",
      " 3   FUEL_USED_4                75861 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            75861 non-null  float64       \n",
      " 5   VALUE_FOB                  75861 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          75861 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         75861 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         75861 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         75861 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         75861 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         75861 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         75861 non-null  float64       \n",
      " 13  FUEL_USED_1                75861 non-null  float64       \n",
      " 14  FLIGHT_ID                  75861 non-null  object        \n",
      " 15  START_FOB                  75861 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            75861 non-null  float64       \n",
      " 17  EXPECTED_FOB               75861 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             75861 non-null  float64       \n",
      " 19  FOB_CHANGE                 75861 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        75861 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             75861 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              75861 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              75861 non-null  float64       \n",
      " 24  LW_RW_DIFF                 75861 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              75861 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        75861 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  75861 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              75861 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             75861 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 17.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Select numerical features only\n",
    "numerical_features = train_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Remove the target column (`LEAK_FLOW_FLAG`) from scaling\n",
    "numerical_features.remove(\"LEAK_FLOW_FLAG\")  \n",
    "\n",
    "# Normalize only numerical features (LSTMs perform better with scaled data)\n",
    "scaler = MinMaxScaler()\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time steps for LSTM (how many past steps to use for each prediction)\n",
    "time_steps = 10  # Use last 10 timesteps to predict next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Convert Data Into LSTM Format (3D: samples, time_steps, features)\n",
    "def create_lstm_sequences(df, features, target, time_steps=10):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Process each flight separately\n",
    "    for flight_id, flight_data in df.groupby(\"FLIGHT_ID\"):\n",
    "        flight_data = flight_data.sort_values(\"UTC_TIME\")  # Ensure correct order\n",
    "        feature_values = flight_data[features].values\n",
    "        target_values = flight_data[target].values\n",
    "\n",
    "        # Create sequences\n",
    "        for i in range(time_steps, len(flight_data)):\n",
    "            X.append(feature_values[i - time_steps:i])  # Last `time_steps` for each row\n",
    "            y.append(target_values[i])  # Next step's target value\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to training & testing sets\n",
    "X_train, y_train = create_lstm_sequences(train_df, numerical_features, \"LEAK_FLOW_FLAG\", time_steps=10)\n",
    "X_test, y_test = create_lstm_sequences(test_df, numerical_features, \"LEAK_FLOW_FLAG\", time_steps=10)\n",
    "\n",
    "# Convert target to categorical (for binary classification)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (74041, 10, 27) (74041, 2)\n",
      "Test Shape: (30102, 10, 27) (30102, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print Final Shape\n",
    "print(\"Train Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test Shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the f1 score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Custom Precision\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    predicted_positives = K.sum(K.round(y_pred))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "# Custom Recall\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    possible_positives = K.sum(K.round(y_true))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "# Custom F1 Score\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * ((prec * rec) / (prec + rec + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=np.unique(np.argmax(y_train, axis=1)),  # Get class labels from one-hot encoding\n",
    "    y=np.argmax(y_train, axis=1)  # Convert one-hot encoding back to labels\n",
    ")\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define Deeper LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation=\"softmax\")  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with Adam Optimizer & Learning Rate Adjustment\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Reduce learning rate\n",
    "    metrics=[\"accuracy\", precision, recall, f1_score, tf.keras.metrics.AUC(name=\"auc\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6360 - auc: 0.7155 - f1_score: 0.6360 - loss: 0.5667 - precision: 0.6360 - recall: 0.6360 - val_accuracy: 0.7469 - val_auc: 0.7932 - val_f1_score: 0.7466 - val_loss: 0.6714 - val_precision: 0.7466 - val_recall: 0.7466\n",
      "Epoch 2/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7222 - auc: 0.8443 - f1_score: 0.7222 - loss: 0.4328 - precision: 0.7222 - recall: 0.7222 - val_accuracy: 0.6234 - val_auc: 0.7020 - val_f1_score: 0.6233 - val_loss: 0.7115 - val_precision: 0.6233 - val_recall: 0.6233\n",
      "Epoch 3/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7173 - auc: 0.8417 - f1_score: 0.7173 - loss: 0.4367 - precision: 0.7173 - recall: 0.7173 - val_accuracy: 0.7140 - val_auc: 0.7771 - val_f1_score: 0.7138 - val_loss: 0.6685 - val_precision: 0.7138 - val_recall: 0.7138\n",
      "Epoch 4/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7215 - auc: 0.8468 - f1_score: 0.7215 - loss: 0.4284 - precision: 0.7215 - recall: 0.7215 - val_accuracy: 0.7020 - val_auc: 0.7592 - val_f1_score: 0.7018 - val_loss: 0.7324 - val_precision: 0.7018 - val_recall: 0.7018\n",
      "Epoch 5/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7309 - auc: 0.8541 - f1_score: 0.7309 - loss: 0.4181 - precision: 0.7309 - recall: 0.7309 - val_accuracy: 0.6978 - val_auc: 0.7676 - val_f1_score: 0.6975 - val_loss: 0.6544 - val_precision: 0.6975 - val_recall: 0.6975\n",
      "Epoch 6/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7300 - auc: 0.8532 - f1_score: 0.7300 - loss: 0.4191 - precision: 0.7300 - recall: 0.7300 - val_accuracy: 0.6845 - val_auc: 0.7364 - val_f1_score: 0.6843 - val_loss: 0.8350 - val_precision: 0.6843 - val_recall: 0.6843\n",
      "Epoch 7/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7267 - auc: 0.8527 - f1_score: 0.7267 - loss: 0.4189 - precision: 0.7267 - recall: 0.7267 - val_accuracy: 0.6372 - val_auc: 0.7425 - val_f1_score: 0.6371 - val_loss: 0.9542 - val_precision: 0.6371 - val_recall: 0.6371\n",
      "Epoch 8/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7345 - auc: 0.8593 - f1_score: 0.7345 - loss: 0.4090 - precision: 0.7345 - recall: 0.7345 - val_accuracy: 0.6291 - val_auc: 0.7317 - val_f1_score: 0.6289 - val_loss: 0.9240 - val_precision: 0.6289 - val_recall: 0.6289\n",
      "Epoch 9/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7351 - auc: 0.8589 - f1_score: 0.7351 - loss: 0.4088 - precision: 0.7351 - recall: 0.7351 - val_accuracy: 0.5765 - val_auc: 0.6721 - val_f1_score: 0.5764 - val_loss: 0.9665 - val_precision: 0.5764 - val_recall: 0.5764\n",
      "Epoch 10/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7337 - auc: 0.8599 - f1_score: 0.7337 - loss: 0.4042 - precision: 0.7337 - recall: 0.7337 - val_accuracy: 0.6031 - val_auc: 0.7292 - val_f1_score: 0.6030 - val_loss: 0.8548 - val_precision: 0.6030 - val_recall: 0.6030\n",
      "Epoch 11/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7321 - auc: 0.8568 - f1_score: 0.7321 - loss: 0.4086 - precision: 0.7321 - recall: 0.7321 - val_accuracy: 0.4303 - val_auc: 0.5401 - val_f1_score: 0.4304 - val_loss: 0.9687 - val_precision: 0.4304 - val_recall: 0.4304\n",
      "Epoch 12/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7337 - auc: 0.8570 - f1_score: 0.7337 - loss: 0.4083 - precision: 0.7337 - recall: 0.7337 - val_accuracy: 0.4290 - val_auc: 0.5581 - val_f1_score: 0.4292 - val_loss: 1.0470 - val_precision: 0.4292 - val_recall: 0.4292\n",
      "Epoch 13/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7318 - auc: 0.8568 - f1_score: 0.7318 - loss: 0.4079 - precision: 0.7318 - recall: 0.7318 - val_accuracy: 0.5464 - val_auc: 0.6905 - val_f1_score: 0.5464 - val_loss: 0.8663 - val_precision: 0.5464 - val_recall: 0.5464\n",
      "Epoch 14/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7319 - auc: 0.8577 - f1_score: 0.7319 - loss: 0.4061 - precision: 0.7319 - recall: 0.7319 - val_accuracy: 0.4930 - val_auc: 0.5813 - val_f1_score: 0.4931 - val_loss: 0.9996 - val_precision: 0.4931 - val_recall: 0.4931\n",
      "Epoch 15/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7361 - auc: 0.8605 - f1_score: 0.7361 - loss: 0.4032 - precision: 0.7361 - recall: 0.7361 - val_accuracy: 0.4916 - val_auc: 0.6085 - val_f1_score: 0.4917 - val_loss: 1.0297 - val_precision: 0.4917 - val_recall: 0.4917\n",
      "Epoch 16/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7317 - auc: 0.8580 - f1_score: 0.7317 - loss: 0.4050 - precision: 0.7317 - recall: 0.7317 - val_accuracy: 0.6991 - val_auc: 0.8069 - val_f1_score: 0.6989 - val_loss: 0.8175 - val_precision: 0.6989 - val_recall: 0.6989\n",
      "Epoch 17/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7361 - auc: 0.8618 - f1_score: 0.7361 - loss: 0.3997 - precision: 0.7361 - recall: 0.7361 - val_accuracy: 0.3680 - val_auc: 0.5061 - val_f1_score: 0.3683 - val_loss: 1.0703 - val_precision: 0.3683 - val_recall: 0.3683\n",
      "Epoch 18/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7294 - auc: 0.8570 - f1_score: 0.7294 - loss: 0.4057 - precision: 0.7294 - recall: 0.7294 - val_accuracy: 0.4382 - val_auc: 0.5648 - val_f1_score: 0.4384 - val_loss: 0.8983 - val_precision: 0.4384 - val_recall: 0.4384\n",
      "Epoch 19/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7353 - auc: 0.8602 - f1_score: 0.7353 - loss: 0.4014 - precision: 0.7353 - recall: 0.7353 - val_accuracy: 0.3631 - val_auc: 0.4857 - val_f1_score: 0.3633 - val_loss: 0.9925 - val_precision: 0.3633 - val_recall: 0.3633\n",
      "Epoch 20/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7328 - auc: 0.8591 - f1_score: 0.7328 - loss: 0.4040 - precision: 0.7328 - recall: 0.7328 - val_accuracy: 0.5293 - val_auc: 0.6632 - val_f1_score: 0.5293 - val_loss: 0.8919 - val_precision: 0.5293 - val_recall: 0.5293\n",
      "Epoch 21/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7399 - auc: 0.8646 - f1_score: 0.7399 - loss: 0.3957 - precision: 0.7399 - recall: 0.7399 - val_accuracy: 0.4048 - val_auc: 0.5471 - val_f1_score: 0.4050 - val_loss: 1.0337 - val_precision: 0.4050 - val_recall: 0.4050\n",
      "Epoch 22/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7378 - auc: 0.8644 - f1_score: 0.7378 - loss: 0.3953 - precision: 0.7378 - recall: 0.7378 - val_accuracy: 0.4804 - val_auc: 0.6085 - val_f1_score: 0.4805 - val_loss: 0.9067 - val_precision: 0.4805 - val_recall: 0.4805\n",
      "Epoch 23/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7339 - auc: 0.8603 - f1_score: 0.7339 - loss: 0.4013 - precision: 0.7339 - recall: 0.7339 - val_accuracy: 0.3631 - val_auc: 0.4488 - val_f1_score: 0.3634 - val_loss: 1.0448 - val_precision: 0.3634 - val_recall: 0.3634\n",
      "Epoch 24/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7391 - auc: 0.8641 - f1_score: 0.7391 - loss: 0.3965 - precision: 0.7391 - recall: 0.7391 - val_accuracy: 0.4787 - val_auc: 0.6192 - val_f1_score: 0.4788 - val_loss: 0.9198 - val_precision: 0.4788 - val_recall: 0.4788\n",
      "Epoch 25/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7398 - auc: 0.8650 - f1_score: 0.7398 - loss: 0.3951 - precision: 0.7398 - recall: 0.7398 - val_accuracy: 0.3651 - val_auc: 0.4928 - val_f1_score: 0.3654 - val_loss: 1.0887 - val_precision: 0.3654 - val_recall: 0.3654\n",
      "Epoch 26/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7341 - auc: 0.8612 - f1_score: 0.7341 - loss: 0.4006 - precision: 0.7341 - recall: 0.7341 - val_accuracy: 0.5803 - val_auc: 0.7377 - val_f1_score: 0.5802 - val_loss: 1.0704 - val_precision: 0.5802 - val_recall: 0.5802\n",
      "Epoch 27/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7411 - auc: 0.8668 - f1_score: 0.7411 - loss: 0.3914 - precision: 0.7411 - recall: 0.7411 - val_accuracy: 0.5062 - val_auc: 0.6704 - val_f1_score: 0.5063 - val_loss: 0.9828 - val_precision: 0.5063 - val_recall: 0.5063\n",
      "Epoch 28/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7396 - auc: 0.8641 - f1_score: 0.7396 - loss: 0.3949 - precision: 0.7396 - recall: 0.7396 - val_accuracy: 0.3656 - val_auc: 0.4896 - val_f1_score: 0.3659 - val_loss: 0.9986 - val_precision: 0.3659 - val_recall: 0.3659\n",
      "Epoch 29/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7399 - auc: 0.8631 - f1_score: 0.7399 - loss: 0.3974 - precision: 0.7399 - recall: 0.7399 - val_accuracy: 0.6369 - val_auc: 0.7884 - val_f1_score: 0.6367 - val_loss: 0.8101 - val_precision: 0.6367 - val_recall: 0.6367\n",
      "Epoch 30/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7451 - auc: 0.8694 - f1_score: 0.7451 - loss: 0.3891 - precision: 0.7451 - recall: 0.7451 - val_accuracy: 0.5202 - val_auc: 0.6387 - val_f1_score: 0.5203 - val_loss: 1.1480 - val_precision: 0.5203 - val_recall: 0.5203\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=30,  # Train longer for better learning\n",
    "    batch_size=64,  # Larger batch sizes for stability\n",
    "    validation_data=(X_test, y_test), \n",
    "    class_weight=class_weight_dict  # Use class weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "model.save(\"lstm_fuel_leak_model101.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m941/941\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "LSTM Model - Accuracy: 0.5202, Precision: 0.2460, Recall: 0.6573, F1-Score: 0.3580, ROC-AUC: 0.5712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Get Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
    "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding back to labels\n",
    "\n",
    "# Compute Classification Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_pred)  # Added ROC-AUC\n",
    "\n",
    "# Print Results\n",
    "print(f\"LSTM Model - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
