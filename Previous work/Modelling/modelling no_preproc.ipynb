{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"combined.csv\"  # Update this path if needed\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Compute LW_RW_DIFF if not already present\n",
    "if 'LW_RW_DIFF' not in df.columns:\n",
    "    # Total Fuel in Left and Right Wing\n",
    "    df['TOTAL_FUEL_LW'] = (df['VALUE_FUEL_QTY_LXT'] + df['VALUE_FUEL_QTY_FT1'] + df['VALUE_FUEL_QTY_FT2'])\n",
    "    df['TOTAL_FUEL_RW'] = (df['VALUE_FUEL_QTY_RXT'] + df['VALUE_FUEL_QTY_FT3'] + df['VALUE_FUEL_QTY_FT4'])\n",
    "\n",
    "    # Fuel Difference\n",
    "    df['LW_RW_DIFF'] = (df['TOTAL_FUEL_LW'] - df['TOTAL_FUEL_RW']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to determine leaks\n",
    "def detect_leak(df, threshold=1500, probability=0.25):\n",
    "    \"\"\"\n",
    "    Function to assign leak labels based on LW_RW_DIFF threshold and probability.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input dataset\n",
    "    threshold (int): Fuel difference threshold to consider leak\n",
    "    probability (float): Probability of assigning a leak when threshold is exceeded\n",
    "    \n",
    "    Returns:\n",
    "    Series: Column with leak labels (0 or 1)\n",
    "    \"\"\"\n",
    "    return np.where((df['LW_RW_DIFF'] > threshold) & (np.random.rand(len(df)) < probability), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply leak detection function\n",
    "df['LEAK'] = detect_leak(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_20288\\254467267.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(x='LEAK', data=df, palette='coolwarm')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.countplot(x='LEAK', data=df, palette='coolwarm')\n",
    "plt.title(\"Distribution of Leak vs No Leak\")\n",
    "plt.xlabel(\" No Leak (0)/Leak (1)\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Add total values above bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for LEAK Column:\n",
      "count    376554.000000\n",
      "mean          0.000837\n",
      "std           0.028911\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: LEAK, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"Summary Statistics for LEAK Column:\")\n",
    "print(df['LEAK'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leak Distribution at Leak Probability of 30%:\n",
      "       Count  Percentage\n",
      "LEAK                    \n",
      "0     376239       99.92\n",
      "1        315        0.08\n"
     ]
    }
   ],
   "source": [
    "# Display value counts (distribution of leaks vs no leaks with percentages)\n",
    "leak_counts = df['LEAK'].value_counts()\n",
    "leak_percentages = df['LEAK'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"\\nLeak Distribution at Leak Probability of 30%:\")\n",
    "print(pd.DataFrame({'Count': leak_counts, 'Percentage': leak_percentages.round(2)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376554 entries, 0 to 376553\n",
      "Data columns (total 35 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   UTC_TIME                   376554 non-null  object \n",
      " 1   FUEL_USED_2                376554 non-null  float64\n",
      " 2   FUEL_USED_3                376554 non-null  float64\n",
      " 3   FUEL_USED_4                376554 non-null  float64\n",
      " 4   FW_GEO_ALTITUDE            376554 non-null  float64\n",
      " 5   VALUE_FOB                  376554 non-null  float64\n",
      " 6   VALUE_FUEL_QTY_CT          376554 non-null  float64\n",
      " 7   VALUE_FUEL_QTY_FT1         376554 non-null  float64\n",
      " 8   VALUE_FUEL_QTY_FT2         376554 non-null  float64\n",
      " 9   VALUE_FUEL_QTY_FT3         376554 non-null  float64\n",
      " 10  VALUE_FUEL_QTY_FT4         376554 non-null  float64\n",
      " 11  VALUE_FUEL_QTY_LXT         376554 non-null  float64\n",
      " 12  VALUE_FUEL_QTY_RXT         376554 non-null  float64\n",
      " 13  FLIGHT_PHASE_COUNT         376554 non-null  float64\n",
      " 14  FUEL_USED_1                376554 non-null  float64\n",
      " 15  Flight                     376554 non-null  float64\n",
      " 16  MSN                        376554 non-null  object \n",
      " 17  NEW_FLIGHT                 376554 non-null  bool   \n",
      " 18  FLIGHT_INSTANCE            376554 non-null  int64  \n",
      " 19  FLIGHT_ID                  376554 non-null  object \n",
      " 20  START_FOB                  376554 non-null  float64\n",
      " 21  TOTAL_FUEL_USED            376554 non-null  float64\n",
      " 22  EXPECTED_FOB               376554 non-null  float64\n",
      " 23  FOB_DIFFERENCE             376554 non-null  float64\n",
      " 24  FOB_CHANGE                 376554 non-null  float64\n",
      " 25  EXPECTED_FOB_CHANGE        376554 non-null  float64\n",
      " 26  FUEL_LEAK_RATE             376554 non-null  float64\n",
      " 27  TOTAL_FUEL_LW              376554 non-null  float64\n",
      " 28  TOTAL_FUEL_RW              376554 non-null  float64\n",
      " 29  LW_RW_DIFF                 376554 non-null  float64\n",
      " 30  FUEL_IN_TANKS              376554 non-null  float64\n",
      " 31  CALC_VALUE_FOB_DIFF        376554 non-null  float64\n",
      " 32  START_FOB_VS_FOB_FUELUSED  376554 non-null  float64\n",
      " 33  ALTITUDE_DIFF              376554 non-null  float64\n",
      " 34  LEAK                       376554 non-null  int32  \n",
      "dtypes: bool(1), float64(29), int32(1), int64(1), object(3)\n",
      "memory usage: 96.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an MSN file (change file path as needed)\n",
    "#msn_file_path = \"msn_10_fuel_leak_signals_preprocessed.csv\"  # Update with the correct file path\n",
    "#msn_df = pd.read_csv(msn_file_path,delimiter=\";\")\n",
    "\n",
    "# Extract column names from the MSN file\n",
    "#msn_columns = msn_df.columns.tolist()\n",
    "\n",
    "# Ensure \"LEAK\" is included in df\n",
    "#msn_columns.append(\"LEAK\")\n",
    "\n",
    "# Filter df to only keep columns that exist in the MSN file + \"LEAK\"\n",
    "#df_filtered = df[msn_columns]\n",
    "\n",
    "# Display the new structure of df\n",
    "#print(f\"Filtered df shape: {df_filtered.shape}\")\n",
    "#print(f\"Columns in filtered df: {list(df_filtered.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Leak Count: 315\n",
      "Train set leak rate: 0.0781% == Training Leak Count: 250 (Expected: 267) \n",
      "Test set leak rate: 0.1151% == Testing Leak Count: 65 (Expected: 48)\n",
      "Training Data Shape: (320070, 35), Testing Data Shape: (56484, 35)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(df, leak_column=\"LEAK\", test_size=0.15):\n",
    "    \"\"\"\n",
    "    Splits the dataset into train and test sets while maintaining the chronological order.\n",
    "    Ensures the same proportion of leaks in train and test sets.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=\"UTC_TIME\")  # Sort by time to prevent data leakage\n",
    "\n",
    "    split_idx = int(len(df) * (1 - test_size))  # Compute split index\n",
    "    train_df = df.iloc[:split_idx]\n",
    "    test_df = df.iloc[split_idx:]\n",
    "\n",
    "    # Count the number of leaks in each dataset\n",
    "    train_leak_count = train_df['LEAK'].sum()\n",
    "    test_leak_count = test_df['LEAK'].sum()\n",
    "    total_leak_count = df['LEAK'].sum()\n",
    "    # Compute expected leak split (should be 75%-25%)\n",
    "    expected_train_leaks = int(total_leak_count * 0.85)\n",
    "    expected_test_leaks = total_leak_count - expected_train_leaks\n",
    "\n",
    "    # Display class distributions\n",
    "    print(f\"Total Leak Count: {total_leak_count}\")\n",
    "    print(f\"Train set leak rate: {100 * train_df[leak_column].mean():.4f}% == Training Leak Count: {train_leak_count} (Expected: {expected_train_leaks}) \")\n",
    "    print(f\"Test set leak rate: {100 * test_df[leak_column].mean():.4f}% == Testing Leak Count: {test_leak_count} (Expected: {expected_test_leaks})\")\n",
    "    print(f\"Training Data Shape: {train_df.shape}, Testing Data Shape: {test_df.shape}\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Apply split\n",
    "train_df, test_df = split_train_test(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 0.0382 - val_loss: 0.0019\n",
      "Epoch 2/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 967us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 3/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 8.6351e-04 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 8.3755e-04 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 8.1042e-04 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 7.9379e-04 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 7.8579e-04 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 7.7150e-04 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 7.5612e-04 - val_loss: 0.0011\n",
      "Epoch 13/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 7.4104e-04 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 7.3199e-04 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 7.2632e-04 - val_loss: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 7.1209e-04 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 7.0689e-04 - val_loss: 9.9997e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 6.9699e-04 - val_loss: 9.9856e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 6.8577e-04 - val_loss: 9.9302e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 6.7923e-04 - val_loss: 9.8875e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 6.7651e-04 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.8390e-04 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 6.6901e-04 - val_loss: 8.7643e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 6.6604e-04 - val_loss: 0.0014\n",
      "Epoch 25/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.5900e-04 - val_loss: 8.6758e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.5531e-04 - val_loss: 8.0183e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4852e-04 - val_loss: 8.0263e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.5131e-04 - val_loss: 8.5389e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.4972e-04 - val_loss: 8.2610e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4566e-04 - val_loss: 7.7404e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4233e-04 - val_loss: 7.9854e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4585e-04 - val_loss: 7.8817e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.3870e-04 - val_loss: 9.5084e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4015e-04 - val_loss: 7.3048e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4365e-04 - val_loss: 8.1396e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.3509e-04 - val_loss: 7.8934e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.4362e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 6.3868e-04 - val_loss: 7.4164e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3887e-04 - val_loss: 7.4758e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3629e-04 - val_loss: 7.9562e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3286e-04 - val_loss: 7.0188e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3318e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3697e-04 - val_loss: 6.7674e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3022e-04 - val_loss: 7.0314e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3002e-04 - val_loss: 6.7233e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.3031e-04 - val_loss: 6.4520e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 6.3024e-04 - val_loss: 7.6417e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: 6.3571e-04 - val_loss: 7.1316e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - loss: 6.2775e-04 - val_loss: 6.8180e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - loss: 6.3578e-04 - val_loss: 6.4439e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - loss: 6.3675e-04 - val_loss: 6.7483e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: 6.2813e-04 - val_loss: 6.3137e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - loss: 6.2538e-04 - val_loss: 7.1765e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2593e-04 - val_loss: 7.0243e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2920e-04 - val_loss: 6.4779e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2421e-04 - val_loss: 7.1966e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3027e-04 - val_loss: 6.2838e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2787e-04 - val_loss: 7.2155e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3221e-04 - val_loss: 6.4163e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2625e-04 - val_loss: 7.0862e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2073e-04 - val_loss: 7.5924e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2736e-04 - val_loss: 9.1288e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.3052e-04 - val_loss: 8.3085e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 6.2985e-04 - val_loss: 7.5361e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3122e-04 - val_loss: 7.4886e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2844e-04 - val_loss: 6.3125e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2456e-04 - val_loss: 6.4206e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3138e-04 - val_loss: 6.6566e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2935e-04 - val_loss: 6.5903e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2714e-04 - val_loss: 8.6604e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2795e-04 - val_loss: 6.5613e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 6.2650e-04 - val_loss: 6.8712e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 6.3000e-04 - val_loss: 6.5152e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 6.3194e-04 - val_loss: 6.3534e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 6.2255e-04 - val_loss: 6.2844e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2606e-04 - val_loss: 8.6153e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.3295e-04 - val_loss: 7.1197e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2642e-04 - val_loss: 7.2520e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3255e-04 - val_loss: 6.6995e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2483e-04 - val_loss: 7.1538e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2337e-04 - val_loss: 6.6943e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2820e-04 - val_loss: 6.2000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3063e-04 - val_loss: 6.7330e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2704e-04 - val_loss: 6.4463e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2402e-04 - val_loss: 8.0151e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2479e-04 - val_loss: 7.0825e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3047e-04 - val_loss: 9.0154e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2672e-04 - val_loss: 7.1758e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2757e-04 - val_loss: 6.8445e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2132e-04 - val_loss: 6.5570e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2846e-04 - val_loss: 6.5636e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.2650e-04 - val_loss: 7.3447e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2486e-04 - val_loss: 6.3354e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2072e-04 - val_loss: 6.6454e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2963e-04 - val_loss: 7.0495e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.3138e-04 - val_loss: 6.4421e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 6.2760e-04 - val_loss: 7.1771e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.3145e-04 - val_loss: 9.8054e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 6.2812e-04 - val_loss: 6.2450e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m7996/7996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 6.3385e-04 - val_loss: 6.5945e-04\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887us/step\n",
      "Confusion Matrix:\n",
      "[[53659  2760]\n",
      " [    0    65]]\n",
      "Accuracy: 0.9511366050562992\n",
      "Precision: 0.023008849557522124\n",
      "Recall: 1.0\n",
      "F1 Score: 0.04498269896193772\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "# Filter out the entries with leaks from training data\n",
    "train_data = train_df[train_df['LEAK'] == 0].drop(columns=['LEAK'])\n",
    "\n",
    "# Identify numerical columns and scale only those\n",
    "numerical_cols = train_data.select_dtypes(include=[np.number]).columns\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data[numerical_cols])\n",
    "\n",
    "# Define the autoencoder model architecture\n",
    "input_dim = train_data_scaled.shape[1]  # Number of features\n",
    "encoding_dim = 14  # Dimension of the encoded representation\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "# Encoder layers\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "# Decoder layers\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder on the scaled training data\n",
    "autoencoder.fit(train_data_scaled, train_data_scaled,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2,\n",
    "                verbose=1)\n",
    "\n",
    "# Prepare the test data by selecting only numerical columns and scaling\n",
    "test_data = test_df[numerical_cols]\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Get the reconstruction loss (MSE) on the test data\n",
    "reconstructions = autoencoder.predict(test_data_scaled)\n",
    "mse = np.mean(np.power(test_data_scaled - reconstructions, 2), axis=1)\n",
    "\n",
    "# Determine the threshold for anomaly detection based on 95th percentile of MSE\n",
    "threshold = np.percentile(mse, 95)\n",
    "\n",
    "# Detect anomalies based on the threshold\n",
    "test_df = test_df.copy()  # Avoid SettingWithCopyWarning\n",
    "test_df['reconstruction_error'] = mse\n",
    "test_df['anomaly'] = test_df['reconstruction_error'] > threshold\n",
    "\n",
    "# Calculate evaluation metrics: Confusion Matrix, Accuracy, Precision, Recall, F1 Score\n",
    "y_true = test_df['LEAK']  # True labels\n",
    "y_pred = test_df['anomaly'].astype(int)  # Predicted labels (0 or 1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)  # Confusion Matrix\n",
    "accuracy = accuracy_score(y_true, y_pred)  # Accuracy\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)  # Precision\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)  # Recall\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)  # F1 Score\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      " [[311901   7919]\n",
      " [   167     83]]\n",
      "Testing Confusion Matrix:\n",
      " [[54823  1596]\n",
      " [   65     0]]\n",
      "Accuracy: 0.9705934423907655\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remove unwanted columns from training and test data\n",
    "test_df = test_df.drop(columns=['reconstruction_error'], errors='ignore')\n",
    "train_df = train_df.drop(columns=['reconstruction_error'], errors='ignore')\n",
    "\n",
    "# Extract numerical features for training and testing\n",
    "train_x = train_df.select_dtypes(include=[np.number]).drop(columns=['LEAK'])\n",
    "test_x = test_df.select_dtypes(include=[np.number]).drop(columns=['LEAK'])\n",
    "\n",
    "# Create an Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination=0.025, random_state=42)\n",
    "\n",
    "# Fit the model on training data\n",
    "isolation_forest.fit(train_x)\n",
    "\n",
    "# Predict anomalies\n",
    "train_x_predictions = isolation_forest.predict(train_x)\n",
    "test_x_predictions = isolation_forest.predict(test_x)\n",
    "\n",
    "# Convert predictions to binary labels (-1 indicates an anomaly)\n",
    "train_x_predictions = (train_x_predictions == -1).astype(int)\n",
    "test_x_predictions = (test_x_predictions == -1).astype(int)\n",
    "\n",
    "# Print the confusion matrix for training data\n",
    "cm_train = confusion_matrix(train_df['LEAK'], train_x_predictions)\n",
    "print(\"Training Confusion Matrix:\\n\", cm_train)\n",
    "\n",
    "# Print the confusion matrix for test data\n",
    "cm_test = confusion_matrix(test_df['LEAK'], test_x_predictions)\n",
    "print(\"Testing Confusion Matrix:\\n\", cm_test)\n",
    "\n",
    "# Print precision, recall, accuracy, and F1 score\n",
    "accuracy = accuracy_score(test_df['LEAK'], test_x_predictions)\n",
    "recall = recall_score(test_df['LEAK'], test_x_predictions, zero_division=0)\n",
    "precision = precision_score(test_df['LEAK'], test_x_predictions, zero_division=0)\n",
    "f1 = f1_score(test_df['LEAK'], test_x_predictions, zero_division=0)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training Confusion Matrix:\n",
      " [[319817      3]\n",
      " [    54    196]]\n",
      "Testing Confusion Matrix:\n",
      " [[56419     0]\n",
      " [   65     0]]\n",
      "Accuracy: 0.9988492316408186\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "F1 Score: 0.0\n",
      "                     Feature  Importance\n",
      "1               EXPECTED_FOB    0.187690\n",
      "2             FOB_DIFFERENCE    0.156515\n",
      "5            TOTAL_FUEL_USED    0.141867\n",
      "8                     lagged    0.134583\n",
      "4  START_FOB_VS_FOB_FUELUSED    0.132620\n",
      "0                  VALUE_FOB    0.124108\n",
      "7             VALUE_FOB_mean    0.087646\n",
      "3                 FOB_CHANGE    0.034971\n",
      "6         FLIGHT_PHASE_COUNT    0.000000\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.5}\n",
      "Best Score: 0.9992189208610617\n",
      "Final Training Confusion Matrix:\n",
      " [[319820      0]\n",
      " [   250      0]]\n",
      "Final Testing Confusion Matrix:\n",
      " [[56419     0]\n",
      " [   65     0]]\n",
      "Final Accuracy: 0.9988492316408186\n",
      "Final Recall: 0.0\n",
      "Final Precision: 0.0\n",
      "Final F1 Score: 0.0\n",
      "                     Feature  Importance\n",
      "8                     lagged    0.224856\n",
      "0                  VALUE_FOB    0.162005\n",
      "5            TOTAL_FUEL_USED    0.144360\n",
      "1               EXPECTED_FOB    0.135601\n",
      "7             VALUE_FOB_mean    0.130420\n",
      "2             FOB_DIFFERENCE    0.116259\n",
      "4  START_FOB_VS_FOB_FUELUSED    0.061638\n",
      "3                 FOB_CHANGE    0.024860\n",
      "6         FLIGHT_PHASE_COUNT    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature selection for XGBoost\n",
    "drop_columns = ['UTC_TIME', 'FLIGHT_ID', 'MSN']\n",
    "selected_features = [\n",
    "    'VALUE_FOB', 'EXPECTED_FOB', 'FOB_DIFFERENCE', 'FOB_CHANGE',\n",
    "    'START_FOB_VS_FOB_FUELUSED', 'TOTAL_FUEL_USED', 'FLIGHT_PHASE_COUNT', 'LEAK'\n",
    "]\n",
    "\n",
    "# Ensure rolling features exist before selecting features\n",
    "train_df['VALUE_FOB_mean'] = train_df['VALUE_FOB'].rolling(window=10).mean()\n",
    "train_df['VALUE_FOB_mean'] = train_df['VALUE_FOB_mean'].fillna(train_df['VALUE_FOB_mean'].mean())\n",
    "train_df['lagged'] = train_df['VALUE_FOB'].shift(1).fillna(train_df['VALUE_FOB'].mean())\n",
    "test_df['VALUE_FOB_mean'] = test_df['VALUE_FOB'].rolling(window=10).mean()\n",
    "test_df['VALUE_FOB_mean'] = test_df['VALUE_FOB_mean'].fillna(test_df['VALUE_FOB_mean'].mean())\n",
    "test_df['lagged'] = test_df['VALUE_FOB'].shift(1).fillna(test_df['VALUE_FOB'].mean())\n",
    "\n",
    "# Add rolling features to selected features\n",
    "selected_features.extend(['VALUE_FOB_mean', 'lagged'])\n",
    "\n",
    "xgboostdata = train_df[selected_features]\n",
    "\n",
    "# Ensure test set contains all necessary features\n",
    "X_train = xgboostdata.drop(columns=['LEAK'])\n",
    "y_train = xgboostdata['LEAK']\n",
    "X_test = test_df[selected_features].drop(columns=['LEAK'], errors='ignore')\n",
    "y_test = test_df['LEAK']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "train_x_predictions = xgb.predict(X_train_scaled)\n",
    "test_x_predictions = xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "cm_train = confusion_matrix(y_train, train_x_predictions)\n",
    "cm_test = confusion_matrix(y_test, test_x_predictions)\n",
    "\n",
    "accuracy = accuracy_score(y_test, test_x_predictions)\n",
    "recall = recall_score(y_test, test_x_predictions, zero_division=0)\n",
    "precision = precision_score(y_test, test_x_predictions, zero_division=0)\n",
    "f1 = f1_score(y_test, test_x_predictions, zero_division=0)\n",
    "\n",
    "print(\"Training Confusion Matrix:\\n\", cm_train)\n",
    "print(\"Testing Confusion Matrix:\\n\", cm_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = xgb.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importances_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances_df)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "tuning_params = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.5, 0.7, 0.9],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=XGBClassifier(), param_grid=tuning_params, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict with the best model\n",
    "train_x_predictions = grid_search.best_estimator_.predict(X_train_scaled)\n",
    "test_x_predictions = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Final evaluation\n",
    "cm_train = confusion_matrix(y_train, train_x_predictions)\n",
    "cm_test = confusion_matrix(y_test, test_x_predictions)\n",
    "accuracy = accuracy_score(y_test, test_x_predictions)\n",
    "recall = recall_score(y_test, test_x_predictions, zero_division=0)\n",
    "precision = precision_score(y_test, test_x_predictions, zero_division=0)\n",
    "f1 = f1_score(y_test, test_x_predictions, zero_division=0)\n",
    "\n",
    "print(\"Final Training Confusion Matrix:\\n\", cm_train)\n",
    "print(\"Final Testing Confusion Matrix:\\n\", cm_test)\n",
    "print(f'Final Accuracy: {accuracy}')\n",
    "print(f'Final Recall: {recall}')\n",
    "print(f'Final Precision: {precision}')\n",
    "print(f'Final F1 Score: {f1}')\n",
    "\n",
    "# Print final feature importance\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UTC_TIME', 'FUEL_USED_2', 'FUEL_USED_3', 'FUEL_USED_4',\n",
       "       'FW_GEO_ALTITUDE', 'VALUE_FOB', 'VALUE_FUEL_QTY_CT',\n",
       "       'VALUE_FUEL_QTY_FT1', 'VALUE_FUEL_QTY_FT2', 'VALUE_FUEL_QTY_FT3',\n",
       "       'VALUE_FUEL_QTY_FT4', 'VALUE_FUEL_QTY_LXT', 'VALUE_FUEL_QTY_RXT',\n",
       "       'FLIGHT_PHASE_COUNT', 'FUEL_USED_1', 'Flight', 'MSN', 'NEW_FLIGHT',\n",
       "       'FLIGHT_INSTANCE', 'FLIGHT_ID', 'START_FOB', 'TOTAL_FUEL_USED',\n",
       "       'EXPECTED_FOB', 'FOB_DIFFERENCE', 'FOB_CHANGE', 'EXPECTED_FOB_CHANGE',\n",
       "       'FUEL_LEAK_RATE', 'TOTAL_FUEL_LW', 'TOTAL_FUEL_RW', 'LW_RW_DIFF',\n",
       "       'FUEL_IN_TANKS', 'CALC_VALUE_FOB_DIFF', 'START_FOB_VS_FOB_FUELUSED',\n",
       "       'ALTITUDE_DIFF', 'LEAK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 3/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 8.6766e-04 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 6.9316e-04 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 5.9478e-04 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 5.4250e-04 - val_loss: 0.0018\n",
      "Epoch 7/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 4.9517e-04 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 4.5838e-04 - val_loss: 0.0023\n",
      "Epoch 9/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 4.3946e-04 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 4.1074e-04 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 3.9339e-04 - val_loss: 0.0026\n",
      "Epoch 12/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 3.7215e-04 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 3.5358e-04 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 3.4102e-04 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 3.2961e-04 - val_loss: 0.0036\n",
      "Epoch 16/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 3.1373e-04 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.9658e-04 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.8760e-04 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.7518e-04 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.6485e-04 - val_loss: 0.0038\n",
      "Epoch 21/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.5355e-04 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.4746e-04 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.3498e-04 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.3298e-04 - val_loss: 0.0038\n",
      "Epoch 25/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.2531e-04 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.1742e-04 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.0800e-04 - val_loss: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 2.0551e-04 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.9612e-04 - val_loss: 0.0039\n",
      "Epoch 30/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.9201e-04 - val_loss: 0.0039\n",
      "Epoch 31/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.8976e-04 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.8374e-04 - val_loss: 0.0040\n",
      "Epoch 33/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.8046e-04 - val_loss: 0.0040\n",
      "Epoch 34/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.7596e-04 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.7228e-04 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.7192e-04 - val_loss: 0.0040\n",
      "Epoch 37/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 1.7208e-04 - val_loss: 0.0038\n",
      "Epoch 38/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.6410e-04 - val_loss: 0.0041\n",
      "Epoch 39/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.6362e-04 - val_loss: 0.0042\n",
      "Epoch 40/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.6074e-04 - val_loss: 0.0040\n",
      "Epoch 41/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.5927e-04 - val_loss: 0.0041\n",
      "Epoch 42/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.5756e-04 - val_loss: 0.0042\n",
      "Epoch 43/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.5795e-04 - val_loss: 0.0041\n",
      "Epoch 44/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.5246e-04 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.5158e-04 - val_loss: 0.0040\n",
      "Epoch 46/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.5020e-04 - val_loss: 0.0040\n",
      "Epoch 47/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.4782e-04 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.4486e-04 - val_loss: 0.0040\n",
      "Epoch 49/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.4416e-04 - val_loss: 0.0042\n",
      "Epoch 50/50\n",
      "\u001b[1m4001/4001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 1.4221e-04 - val_loss: 0.0041\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "Confusion Matrix:\n",
      "[[53659  2760]\n",
      " [    0    65]]\n",
      "Accuracy: 0.9511366050562992\n",
      "Precision: 0.023008849557522124\n",
      "Recall: 1.0\n",
      "F1 Score: 0.04498269896193772\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed\n",
    "\n",
    "# Identify numerical columns and scale only those\n",
    "numerical_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_df[numerical_cols])\n",
    "test_data_scaled = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "time_steps = 10  # Number of time steps for LSTM input\n",
    "train_data_reshaped = train_data_scaled.reshape((train_data_scaled.shape[0], 1, train_data_scaled.shape[1]))\n",
    "test_data_reshaped = test_data_scaled.reshape((test_data_scaled.shape[0], 1, test_data_scaled.shape[1]))\n",
    "\n",
    "# Define LSTM Autoencoder model\n",
    "model = Sequential([\n",
    "    LSTM(128, activation='relu', input_shape=(1, train_data_scaled.shape[1]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, activation='relu', return_sequences=False),\n",
    "    RepeatVector(1),\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(128, activation='relu', return_sequences=True),\n",
    "    TimeDistributed(Dense(train_data_scaled.shape[1]))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the LSTM Autoencoder\n",
    "model.fit(train_data_reshaped, train_data_reshaped,\n",
    "          epochs=50,\n",
    "          batch_size=64,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          verbose=1)\n",
    "\n",
    "# Get reconstruction loss (MSE) on the test data\n",
    "reconstructions = model.predict(test_data_reshaped)\n",
    "mse = np.mean(np.power(test_data_reshaped - reconstructions, 2), axis=(1, 2))\n",
    "\n",
    "# Determine anomaly threshold based on 95th percentile\n",
    "threshold = np.percentile(mse, 95)\n",
    "\n",
    "# Detect anomalies based on the threshold\n",
    "test_df = test_df.copy()\n",
    "test_df['reconstruction_error'] = mse\n",
    "test_df['anomaly'] = test_df['reconstruction_error'] > threshold\n",
    "\n",
    "# Evaluation metrics\n",
    "y_true = test_df['LEAK']\n",
    "y_pred = test_df['anomaly'].astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
