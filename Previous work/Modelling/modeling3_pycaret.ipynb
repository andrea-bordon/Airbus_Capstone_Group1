{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_simulated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'UTC_TIME' column to datetime format and sort by time\n",
    "df['UTC_TIME'] = pd.to_datetime(df['UTC_TIME'])\n",
    "df.sort_values(by=['FLIGHT_INSTANCE', 'UTC_TIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelvant columns\n",
    "df = df.drop(columns=['FLIGHT_PHASE_COUNT', 'Flight','MSN', 'FLIGHT_INSTANCE', 'NEW_FLIGHT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 376554 entries, 0 to 337922\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   UTC_TIME                   376554 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                376554 non-null  float64       \n",
      " 2   FUEL_USED_3                376554 non-null  float64       \n",
      " 3   FUEL_USED_4                376554 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            376554 non-null  float64       \n",
      " 5   VALUE_FOB                  376554 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          376554 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         376554 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         376554 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         376554 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         376554 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         376554 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         376554 non-null  float64       \n",
      " 13  FUEL_USED_1                376554 non-null  float64       \n",
      " 14  FLIGHT_ID                  376554 non-null  object        \n",
      " 15  START_FOB                  376554 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            376554 non-null  float64       \n",
      " 17  EXPECTED_FOB               376554 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             376554 non-null  float64       \n",
      " 19  FOB_CHANGE                 376554 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        376554 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             376554 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              376554 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              376554 non-null  float64       \n",
      " 24  LW_RW_DIFF                 376554 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              376554 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        376554 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  376554 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              376554 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             376554 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 89.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    343079\n",
       "1     33475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LEAK_FLOW_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting out all No-Leak Flights before 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify flights with leaks (Keep these)\n",
    "leak_flights = df[df[\"LEAK_FLOW_FLAG\"] == 1][\"FLIGHT_ID\"].unique()\n",
    "\n",
    "# Identify no-leak flights that started before 2017\n",
    "no_leak_flights = df[df[\"LEAK_FLOW_FLAG\"] == 0].groupby(\"FLIGHT_ID\")[\"UTC_TIME\"].min()\n",
    "no_leak_flights_to_remove = no_leak_flights[no_leak_flights < \"2017-10-22\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Keep all leak flights + no-leak flights that started in 2017 or later\n",
    "df_filtered = df[df[\"FLIGHT_ID\"].isin(leak_flights) | ~df[\"FLIGHT_ID\"].isin(no_leak_flights_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 376554\n",
      "Filtered dataset size: 247584\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataset size: {df.shape[0]}\")\n",
    "print(f\"Filtered dataset size: {df_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    214109\n",
       "1     33475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['LEAK_FLOW_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median Number of Leaks per Flight: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Get mean of leaks per flight (better than sum bc each flight may have varying flight durations)\n",
    "flight_leak_counts = df_filtered.groupby(\"FLIGHT_ID\")[\"LEAK_FLOW_FLAG\"].mean()\n",
    "\n",
    "#  Compute the media Number of Leaks per Flight\n",
    "median_leaks_per_flight = flight_leak_counts[flight_leak_counts > 0].median()\n",
    "print(f\"median Number of Leaks per Flight: {median_leaks_per_flight:.2f}\")\n",
    "\n",
    "# Select flights where the number of leaks is higher than the median\n",
    "flights_with_leaks = flight_leak_counts[flight_leak_counts > median_leaks_per_flight].index\n",
    "\n",
    "# EXTREME Reduction: Only keep 1% as many no-leak flights as leak flights\n",
    "num_leak_flights = len(flights_with_leaks)  # Total number of flights with leaks\n",
    "num_no_leak_flights = int(num_leak_flights * 0.80)  # Cut down no-leak flights aggressively\n",
    "\n",
    "# Sample only the reduced number of no-leak flights\n",
    "flights_no_leaks = flight_leak_counts[flight_leak_counts == 0].sample(\n",
    "    n=num_no_leak_flights, \n",
    "    random_state=42\n",
    ").index\n",
    "\n",
    "# Keep only selected flights (Preserves sequences!)\n",
    "df_balanced = df_filtered[df_filtered[\"FLIGHT_ID\"].isin(flights_with_leaks.union(flights_no_leaks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    76.336882\n",
       "1    23.663118\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced[\"LEAK_FLOW_FLAG\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106423 entries, 153 to 337922\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   UTC_TIME                   106423 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                106423 non-null  float64       \n",
      " 2   FUEL_USED_3                106423 non-null  float64       \n",
      " 3   FUEL_USED_4                106423 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            106423 non-null  float64       \n",
      " 5   VALUE_FOB                  106423 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          106423 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         106423 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         106423 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         106423 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         106423 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         106423 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         106423 non-null  float64       \n",
      " 13  FUEL_USED_1                106423 non-null  float64       \n",
      " 14  FLIGHT_ID                  106423 non-null  object        \n",
      " 15  START_FOB                  106423 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            106423 non-null  float64       \n",
      " 17  EXPECTED_FOB               106423 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             106423 non-null  float64       \n",
      " 19  FOB_CHANGE                 106423 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        106423 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             106423 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              106423 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              106423 non-null  float64       \n",
      " 24  LW_RW_DIFF                 106423 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              106423 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        106423 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  106423 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              106423 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             106423 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all features (except the target)\n",
    "features = df_balanced.columns.tolist()\n",
    "features.remove('LEAK_FLOW_FLAG')  # Remove target column from features\n",
    "\n",
    "# Target variable\n",
    "target = 'LEAK_FLOW_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features (memory for time-series)\n",
    "def create_lag_features(df, features, lags=[1, 3, 5, 10]):\n",
    "    \"\"\"\n",
    "    Adds past values (lags) as new features to help capture time dependency.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        for feature in features:\n",
    "            df[f'{feature}_lag{lag}'] = df.groupby('FLIGHT_ID')[feature].shift(lag)\n",
    "    return df\n",
    "\n",
    "df_balanced = create_lag_features(df_balanced, features, lags=[1, 3, 5, 10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values (due to lagging)\n",
    "df_balanced.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 104143 entries, 163 to 337922\n",
      "Data columns (total 146 columns):\n",
      " #    Column                           Non-Null Count   Dtype         \n",
      "---   ------                           --------------   -----         \n",
      " 0    UTC_TIME                         104143 non-null  datetime64[ns]\n",
      " 1    FUEL_USED_2                      104143 non-null  float64       \n",
      " 2    FUEL_USED_3                      104143 non-null  float64       \n",
      " 3    FUEL_USED_4                      104143 non-null  float64       \n",
      " 4    FW_GEO_ALTITUDE                  104143 non-null  float64       \n",
      " 5    VALUE_FOB                        104143 non-null  float64       \n",
      " 6    VALUE_FUEL_QTY_CT                104143 non-null  float64       \n",
      " 7    VALUE_FUEL_QTY_FT1               104143 non-null  float64       \n",
      " 8    VALUE_FUEL_QTY_FT2               104143 non-null  float64       \n",
      " 9    VALUE_FUEL_QTY_FT3               104143 non-null  float64       \n",
      " 10   VALUE_FUEL_QTY_FT4               104143 non-null  float64       \n",
      " 11   VALUE_FUEL_QTY_LXT               104143 non-null  float64       \n",
      " 12   VALUE_FUEL_QTY_RXT               104143 non-null  float64       \n",
      " 13   FUEL_USED_1                      104143 non-null  float64       \n",
      " 14   FLIGHT_ID                        104143 non-null  object        \n",
      " 15   START_FOB                        104143 non-null  float64       \n",
      " 16   TOTAL_FUEL_USED                  104143 non-null  float64       \n",
      " 17   EXPECTED_FOB                     104143 non-null  float64       \n",
      " 18   FOB_DIFFERENCE                   104143 non-null  float64       \n",
      " 19   FOB_CHANGE                       104143 non-null  float64       \n",
      " 20   EXPECTED_FOB_CHANGE              104143 non-null  float64       \n",
      " 21   FUEL_LEAK_RATE                   104143 non-null  float64       \n",
      " 22   TOTAL_FUEL_LW                    104143 non-null  float64       \n",
      " 23   TOTAL_FUEL_RW                    104143 non-null  float64       \n",
      " 24   LW_RW_DIFF                       104143 non-null  float64       \n",
      " 25   FUEL_IN_TANKS                    104143 non-null  float64       \n",
      " 26   CALC_VALUE_FOB_DIFF              104143 non-null  float64       \n",
      " 27   START_FOB_VS_FOB_FUELUSED        104143 non-null  float64       \n",
      " 28   ALTITUDE_DIFF                    104143 non-null  float64       \n",
      " 29   LEAK_FLOW_FLAG                   104143 non-null  int64         \n",
      " 30   UTC_TIME_lag1                    104143 non-null  datetime64[ns]\n",
      " 31   FUEL_USED_2_lag1                 104143 non-null  float64       \n",
      " 32   FUEL_USED_3_lag1                 104143 non-null  float64       \n",
      " 33   FUEL_USED_4_lag1                 104143 non-null  float64       \n",
      " 34   FW_GEO_ALTITUDE_lag1             104143 non-null  float64       \n",
      " 35   VALUE_FOB_lag1                   104143 non-null  float64       \n",
      " 36   VALUE_FUEL_QTY_CT_lag1           104143 non-null  float64       \n",
      " 37   VALUE_FUEL_QTY_FT1_lag1          104143 non-null  float64       \n",
      " 38   VALUE_FUEL_QTY_FT2_lag1          104143 non-null  float64       \n",
      " 39   VALUE_FUEL_QTY_FT3_lag1          104143 non-null  float64       \n",
      " 40   VALUE_FUEL_QTY_FT4_lag1          104143 non-null  float64       \n",
      " 41   VALUE_FUEL_QTY_LXT_lag1          104143 non-null  float64       \n",
      " 42   VALUE_FUEL_QTY_RXT_lag1          104143 non-null  float64       \n",
      " 43   FUEL_USED_1_lag1                 104143 non-null  float64       \n",
      " 44   FLIGHT_ID_lag1                   104143 non-null  object        \n",
      " 45   START_FOB_lag1                   104143 non-null  float64       \n",
      " 46   TOTAL_FUEL_USED_lag1             104143 non-null  float64       \n",
      " 47   EXPECTED_FOB_lag1                104143 non-null  float64       \n",
      " 48   FOB_DIFFERENCE_lag1              104143 non-null  float64       \n",
      " 49   FOB_CHANGE_lag1                  104143 non-null  float64       \n",
      " 50   EXPECTED_FOB_CHANGE_lag1         104143 non-null  float64       \n",
      " 51   FUEL_LEAK_RATE_lag1              104143 non-null  float64       \n",
      " 52   TOTAL_FUEL_LW_lag1               104143 non-null  float64       \n",
      " 53   TOTAL_FUEL_RW_lag1               104143 non-null  float64       \n",
      " 54   LW_RW_DIFF_lag1                  104143 non-null  float64       \n",
      " 55   FUEL_IN_TANKS_lag1               104143 non-null  float64       \n",
      " 56   CALC_VALUE_FOB_DIFF_lag1         104143 non-null  float64       \n",
      " 57   START_FOB_VS_FOB_FUELUSED_lag1   104143 non-null  float64       \n",
      " 58   ALTITUDE_DIFF_lag1               104143 non-null  float64       \n",
      " 59   UTC_TIME_lag3                    104143 non-null  datetime64[ns]\n",
      " 60   FUEL_USED_2_lag3                 104143 non-null  float64       \n",
      " 61   FUEL_USED_3_lag3                 104143 non-null  float64       \n",
      " 62   FUEL_USED_4_lag3                 104143 non-null  float64       \n",
      " 63   FW_GEO_ALTITUDE_lag3             104143 non-null  float64       \n",
      " 64   VALUE_FOB_lag3                   104143 non-null  float64       \n",
      " 65   VALUE_FUEL_QTY_CT_lag3           104143 non-null  float64       \n",
      " 66   VALUE_FUEL_QTY_FT1_lag3          104143 non-null  float64       \n",
      " 67   VALUE_FUEL_QTY_FT2_lag3          104143 non-null  float64       \n",
      " 68   VALUE_FUEL_QTY_FT3_lag3          104143 non-null  float64       \n",
      " 69   VALUE_FUEL_QTY_FT4_lag3          104143 non-null  float64       \n",
      " 70   VALUE_FUEL_QTY_LXT_lag3          104143 non-null  float64       \n",
      " 71   VALUE_FUEL_QTY_RXT_lag3          104143 non-null  float64       \n",
      " 72   FUEL_USED_1_lag3                 104143 non-null  float64       \n",
      " 73   FLIGHT_ID_lag3                   104143 non-null  object        \n",
      " 74   START_FOB_lag3                   104143 non-null  float64       \n",
      " 75   TOTAL_FUEL_USED_lag3             104143 non-null  float64       \n",
      " 76   EXPECTED_FOB_lag3                104143 non-null  float64       \n",
      " 77   FOB_DIFFERENCE_lag3              104143 non-null  float64       \n",
      " 78   FOB_CHANGE_lag3                  104143 non-null  float64       \n",
      " 79   EXPECTED_FOB_CHANGE_lag3         104143 non-null  float64       \n",
      " 80   FUEL_LEAK_RATE_lag3              104143 non-null  float64       \n",
      " 81   TOTAL_FUEL_LW_lag3               104143 non-null  float64       \n",
      " 82   TOTAL_FUEL_RW_lag3               104143 non-null  float64       \n",
      " 83   LW_RW_DIFF_lag3                  104143 non-null  float64       \n",
      " 84   FUEL_IN_TANKS_lag3               104143 non-null  float64       \n",
      " 85   CALC_VALUE_FOB_DIFF_lag3         104143 non-null  float64       \n",
      " 86   START_FOB_VS_FOB_FUELUSED_lag3   104143 non-null  float64       \n",
      " 87   ALTITUDE_DIFF_lag3               104143 non-null  float64       \n",
      " 88   UTC_TIME_lag5                    104143 non-null  datetime64[ns]\n",
      " 89   FUEL_USED_2_lag5                 104143 non-null  float64       \n",
      " 90   FUEL_USED_3_lag5                 104143 non-null  float64       \n",
      " 91   FUEL_USED_4_lag5                 104143 non-null  float64       \n",
      " 92   FW_GEO_ALTITUDE_lag5             104143 non-null  float64       \n",
      " 93   VALUE_FOB_lag5                   104143 non-null  float64       \n",
      " 94   VALUE_FUEL_QTY_CT_lag5           104143 non-null  float64       \n",
      " 95   VALUE_FUEL_QTY_FT1_lag5          104143 non-null  float64       \n",
      " 96   VALUE_FUEL_QTY_FT2_lag5          104143 non-null  float64       \n",
      " 97   VALUE_FUEL_QTY_FT3_lag5          104143 non-null  float64       \n",
      " 98   VALUE_FUEL_QTY_FT4_lag5          104143 non-null  float64       \n",
      " 99   VALUE_FUEL_QTY_LXT_lag5          104143 non-null  float64       \n",
      " 100  VALUE_FUEL_QTY_RXT_lag5          104143 non-null  float64       \n",
      " 101  FUEL_USED_1_lag5                 104143 non-null  float64       \n",
      " 102  FLIGHT_ID_lag5                   104143 non-null  object        \n",
      " 103  START_FOB_lag5                   104143 non-null  float64       \n",
      " 104  TOTAL_FUEL_USED_lag5             104143 non-null  float64       \n",
      " 105  EXPECTED_FOB_lag5                104143 non-null  float64       \n",
      " 106  FOB_DIFFERENCE_lag5              104143 non-null  float64       \n",
      " 107  FOB_CHANGE_lag5                  104143 non-null  float64       \n",
      " 108  EXPECTED_FOB_CHANGE_lag5         104143 non-null  float64       \n",
      " 109  FUEL_LEAK_RATE_lag5              104143 non-null  float64       \n",
      " 110  TOTAL_FUEL_LW_lag5               104143 non-null  float64       \n",
      " 111  TOTAL_FUEL_RW_lag5               104143 non-null  float64       \n",
      " 112  LW_RW_DIFF_lag5                  104143 non-null  float64       \n",
      " 113  FUEL_IN_TANKS_lag5               104143 non-null  float64       \n",
      " 114  CALC_VALUE_FOB_DIFF_lag5         104143 non-null  float64       \n",
      " 115  START_FOB_VS_FOB_FUELUSED_lag5   104143 non-null  float64       \n",
      " 116  ALTITUDE_DIFF_lag5               104143 non-null  float64       \n",
      " 117  UTC_TIME_lag10                   104143 non-null  datetime64[ns]\n",
      " 118  FUEL_USED_2_lag10                104143 non-null  float64       \n",
      " 119  FUEL_USED_3_lag10                104143 non-null  float64       \n",
      " 120  FUEL_USED_4_lag10                104143 non-null  float64       \n",
      " 121  FW_GEO_ALTITUDE_lag10            104143 non-null  float64       \n",
      " 122  VALUE_FOB_lag10                  104143 non-null  float64       \n",
      " 123  VALUE_FUEL_QTY_CT_lag10          104143 non-null  float64       \n",
      " 124  VALUE_FUEL_QTY_FT1_lag10         104143 non-null  float64       \n",
      " 125  VALUE_FUEL_QTY_FT2_lag10         104143 non-null  float64       \n",
      " 126  VALUE_FUEL_QTY_FT3_lag10         104143 non-null  float64       \n",
      " 127  VALUE_FUEL_QTY_FT4_lag10         104143 non-null  float64       \n",
      " 128  VALUE_FUEL_QTY_LXT_lag10         104143 non-null  float64       \n",
      " 129  VALUE_FUEL_QTY_RXT_lag10         104143 non-null  float64       \n",
      " 130  FUEL_USED_1_lag10                104143 non-null  float64       \n",
      " 131  FLIGHT_ID_lag10                  104143 non-null  object        \n",
      " 132  START_FOB_lag10                  104143 non-null  float64       \n",
      " 133  TOTAL_FUEL_USED_lag10            104143 non-null  float64       \n",
      " 134  EXPECTED_FOB_lag10               104143 non-null  float64       \n",
      " 135  FOB_DIFFERENCE_lag10             104143 non-null  float64       \n",
      " 136  FOB_CHANGE_lag10                 104143 non-null  float64       \n",
      " 137  EXPECTED_FOB_CHANGE_lag10        104143 non-null  float64       \n",
      " 138  FUEL_LEAK_RATE_lag10             104143 non-null  float64       \n",
      " 139  TOTAL_FUEL_LW_lag10              104143 non-null  float64       \n",
      " 140  TOTAL_FUEL_RW_lag10              104143 non-null  float64       \n",
      " 141  LW_RW_DIFF_lag10                 104143 non-null  float64       \n",
      " 142  FUEL_IN_TANKS_lag10              104143 non-null  float64       \n",
      " 143  CALC_VALUE_FOB_DIFF_lag10        104143 non-null  float64       \n",
      " 144  START_FOB_VS_FOB_FUELUSED_lag10  104143 non-null  float64       \n",
      " 145  ALTITUDE_DIFF_lag10              104143 non-null  float64       \n",
      "dtypes: datetime64[ns](5), float64(135), int64(1), object(5)\n",
      "memory usage: 116.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_balanced.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort flights by their first recorded timestamp\n",
    "flight_start_times = df_balanced.groupby(\"FLIGHT_ID\")[\"UTC_TIME\"].min().sort_values()\n",
    "\n",
    "# Define the split point (80% train, 20% test)\n",
    "split_index = int(len(flight_start_times) * 0.8)  # Get the 80% split point\n",
    "\n",
    "# Assign the first 80% of flights to training, last 20% to testing\n",
    "train_flights = flight_start_times.index[:split_index]  # First 80% of flights\n",
    "test_flights = flight_start_times.index[split_index:]  # Last 20% of flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_balanced[df_balanced[\"FLIGHT_ID\"].isin(train_flights)]\n",
    "test_df = df_balanced[df_balanced[\"FLIGHT_ID\"].isin(test_flights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEAK_FLOW_FLAG\n",
       "0    74.962521\n",
       "1    25.037479\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"LEAK_FLOW_FLAG\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index (PyCaret needs a clean index)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pycaret Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8ebcb_row10_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8ebcb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8ebcb_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_8ebcb_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8ebcb_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_8ebcb_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8ebcb_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_8ebcb_row1_col1\" class=\"data row1 col1\" >LEAK_FLOW_FLAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8ebcb_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_8ebcb_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8ebcb_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_8ebcb_row3_col1\" class=\"data row3 col1\" >(74041, 151)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8ebcb_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_8ebcb_row4_col1\" class=\"data row4 col1\" >(74041, 161)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8ebcb_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_8ebcb_row5_col1\" class=\"data row5 col1\" >(59232, 161)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_8ebcb_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_8ebcb_row6_col1\" class=\"data row6 col1\" >(14809, 161)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_8ebcb_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_8ebcb_row7_col1\" class=\"data row7 col1\" >135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_8ebcb_row8_col0\" class=\"data row8 col0\" >Date features</td>\n",
       "      <td id=\"T_8ebcb_row8_col1\" class=\"data row8 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_8ebcb_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_8ebcb_row9_col1\" class=\"data row9 col1\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_8ebcb_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_8ebcb_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_8ebcb_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_8ebcb_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_8ebcb_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_8ebcb_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_8ebcb_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_8ebcb_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_8ebcb_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_8ebcb_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_8ebcb_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_8ebcb_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_8ebcb_row16_col0\" class=\"data row16 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_8ebcb_row16_col1\" class=\"data row16 col1\" >TimeSeriesSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_8ebcb_row17_col0\" class=\"data row17 col0\" >Fold Number</td>\n",
       "      <td id=\"T_8ebcb_row17_col1\" class=\"data row17 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_8ebcb_row18_col0\" class=\"data row18 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_8ebcb_row18_col1\" class=\"data row18 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_8ebcb_row19_col0\" class=\"data row19 col0\" >Use GPU</td>\n",
       "      <td id=\"T_8ebcb_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_8ebcb_row20_col0\" class=\"data row20 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_8ebcb_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_8ebcb_row21_col0\" class=\"data row21 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_8ebcb_row21_col1\" class=\"data row21 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ebcb_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_8ebcb_row22_col0\" class=\"data row22 col0\" >USI</td>\n",
       "      <td id=\"T_8ebcb_row22_col1\" class=\"data row22 col1\" >cacf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10cf03f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use `timeseries` fold strategy while enforcing all required settings\n",
    "clf_setup = setup(\n",
    "    data=train_df, \n",
    "    target=target,\n",
    "    train_size=0.8,\n",
    "    session_id=42, \n",
    "    fold_strategy=\"timeseries\",  # Time-based validation\n",
    "    fold=5,\n",
    "    data_split_shuffle=False,  # Prevents PyCaret from shuffling time order\n",
    "    fold_shuffle=False,  # Ensures validation comes AFTER training\n",
    "    data_split_stratify=False  # Disables stratification (not allowed with time-series)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6802d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6802d_row0_col0, #T_6802d_row0_col1, #T_6802d_row0_col2, #T_6802d_row0_col4, #T_6802d_row0_col5, #T_6802d_row0_col6, #T_6802d_row0_col7, #T_6802d_row1_col0, #T_6802d_row1_col1, #T_6802d_row1_col3, #T_6802d_row1_col4, #T_6802d_row2_col0, #T_6802d_row2_col1, #T_6802d_row2_col2, #T_6802d_row2_col3, #T_6802d_row2_col4, #T_6802d_row2_col5, #T_6802d_row2_col6, #T_6802d_row2_col7, #T_6802d_row3_col0, #T_6802d_row3_col2, #T_6802d_row3_col3, #T_6802d_row3_col4, #T_6802d_row3_col5, #T_6802d_row3_col6, #T_6802d_row3_col7, #T_6802d_row4_col0, #T_6802d_row4_col1, #T_6802d_row4_col2, #T_6802d_row4_col3, #T_6802d_row4_col4, #T_6802d_row4_col5, #T_6802d_row4_col6, #T_6802d_row4_col7, #T_6802d_row5_col0, #T_6802d_row5_col1, #T_6802d_row5_col2, #T_6802d_row5_col3, #T_6802d_row5_col4, #T_6802d_row5_col5, #T_6802d_row5_col6, #T_6802d_row5_col7, #T_6802d_row6_col0, #T_6802d_row6_col1, #T_6802d_row6_col2, #T_6802d_row6_col3, #T_6802d_row6_col4, #T_6802d_row6_col5, #T_6802d_row6_col6, #T_6802d_row6_col7, #T_6802d_row7_col0, #T_6802d_row7_col1, #T_6802d_row7_col2, #T_6802d_row7_col3, #T_6802d_row7_col4, #T_6802d_row7_col5, #T_6802d_row7_col6, #T_6802d_row7_col7, #T_6802d_row8_col0, #T_6802d_row8_col1, #T_6802d_row8_col2, #T_6802d_row8_col3, #T_6802d_row8_col4, #T_6802d_row8_col5, #T_6802d_row8_col6, #T_6802d_row8_col7, #T_6802d_row9_col0, #T_6802d_row9_col1, #T_6802d_row9_col2, #T_6802d_row9_col3, #T_6802d_row9_col4, #T_6802d_row9_col5, #T_6802d_row9_col6, #T_6802d_row9_col7, #T_6802d_row10_col0, #T_6802d_row10_col1, #T_6802d_row10_col2, #T_6802d_row10_col3, #T_6802d_row10_col4, #T_6802d_row10_col5, #T_6802d_row10_col6, #T_6802d_row10_col7, #T_6802d_row11_col0, #T_6802d_row11_col1, #T_6802d_row11_col2, #T_6802d_row11_col3, #T_6802d_row11_col4, #T_6802d_row11_col5, #T_6802d_row11_col6, #T_6802d_row11_col7, #T_6802d_row12_col0, #T_6802d_row12_col1, #T_6802d_row12_col2, #T_6802d_row12_col3, #T_6802d_row12_col5, #T_6802d_row12_col6, #T_6802d_row12_col7, #T_6802d_row13_col0, #T_6802d_row13_col1, #T_6802d_row13_col2, #T_6802d_row13_col3, #T_6802d_row13_col4, #T_6802d_row13_col5, #T_6802d_row13_col6, #T_6802d_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6802d_row0_col3, #T_6802d_row1_col2, #T_6802d_row1_col5, #T_6802d_row1_col6, #T_6802d_row1_col7, #T_6802d_row3_col1, #T_6802d_row12_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_6802d_row0_col8, #T_6802d_row1_col8, #T_6802d_row2_col8, #T_6802d_row3_col8, #T_6802d_row4_col8, #T_6802d_row5_col8, #T_6802d_row6_col8, #T_6802d_row7_col8, #T_6802d_row8_col8, #T_6802d_row9_col8, #T_6802d_row10_col8, #T_6802d_row11_col8, #T_6802d_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_6802d_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6802d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6802d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6802d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6802d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_6802d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_6802d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_6802d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_6802d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_6802d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_6802d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row0\" class=\"row_heading level0 row0\" >qda</th>\n",
       "      <td id=\"T_6802d_row0_col0\" class=\"data row0 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_6802d_row0_col1\" class=\"data row0 col1\" >0.3612</td>\n",
       "      <td id=\"T_6802d_row0_col2\" class=\"data row0 col2\" >0.4757</td>\n",
       "      <td id=\"T_6802d_row0_col3\" class=\"data row0 col3\" >0.7921</td>\n",
       "      <td id=\"T_6802d_row0_col4\" class=\"data row0 col4\" >0.2441</td>\n",
       "      <td id=\"T_6802d_row0_col5\" class=\"data row0 col5\" >0.3623</td>\n",
       "      <td id=\"T_6802d_row0_col6\" class=\"data row0 col6\" >-0.0005</td>\n",
       "      <td id=\"T_6802d_row0_col7\" class=\"data row0 col7\" >0.0070</td>\n",
       "      <td id=\"T_6802d_row0_col8\" class=\"data row0 col8\" >0.3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_6802d_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_6802d_row1_col1\" class=\"data row1 col1\" >0.7607</td>\n",
       "      <td id=\"T_6802d_row1_col2\" class=\"data row1 col2\" >0.8244</td>\n",
       "      <td id=\"T_6802d_row1_col3\" class=\"data row1 col3\" >0.7528</td>\n",
       "      <td id=\"T_6802d_row1_col4\" class=\"data row1 col4\" >0.5105</td>\n",
       "      <td id=\"T_6802d_row1_col5\" class=\"data row1 col5\" >0.6051</td>\n",
       "      <td id=\"T_6802d_row1_col6\" class=\"data row1 col6\" >0.4237</td>\n",
       "      <td id=\"T_6802d_row1_col7\" class=\"data row1 col7\" >0.4419</td>\n",
       "      <td id=\"T_6802d_row1_col8\" class=\"data row1 col8\" >26.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row2\" class=\"row_heading level0 row2\" >ada</th>\n",
       "      <td id=\"T_6802d_row2_col0\" class=\"data row2 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_6802d_row2_col1\" class=\"data row2 col1\" >0.7592</td>\n",
       "      <td id=\"T_6802d_row2_col2\" class=\"data row2 col2\" >0.8222</td>\n",
       "      <td id=\"T_6802d_row2_col3\" class=\"data row2 col3\" >0.6764</td>\n",
       "      <td id=\"T_6802d_row2_col4\" class=\"data row2 col4\" >0.5114</td>\n",
       "      <td id=\"T_6802d_row2_col5\" class=\"data row2 col5\" >0.5728</td>\n",
       "      <td id=\"T_6802d_row2_col6\" class=\"data row2 col6\" >0.3912</td>\n",
       "      <td id=\"T_6802d_row2_col7\" class=\"data row2 col7\" >0.4054</td>\n",
       "      <td id=\"T_6802d_row2_col8\" class=\"data row2 col8\" >5.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_6802d_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_6802d_row3_col1\" class=\"data row3 col1\" >0.7614</td>\n",
       "      <td id=\"T_6802d_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row3_col3\" class=\"data row3 col3\" >0.5731</td>\n",
       "      <td id=\"T_6802d_row3_col4\" class=\"data row3 col4\" >0.5161</td>\n",
       "      <td id=\"T_6802d_row3_col5\" class=\"data row3 col5\" >0.5421</td>\n",
       "      <td id=\"T_6802d_row3_col6\" class=\"data row3 col6\" >0.3651</td>\n",
       "      <td id=\"T_6802d_row3_col7\" class=\"data row3 col7\" >0.3666</td>\n",
       "      <td id=\"T_6802d_row3_col8\" class=\"data row3 col8\" >0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row4\" class=\"row_heading level0 row4\" >dt</th>\n",
       "      <td id=\"T_6802d_row4_col0\" class=\"data row4 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_6802d_row4_col1\" class=\"data row4 col1\" >0.7589</td>\n",
       "      <td id=\"T_6802d_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row4_col3\" class=\"data row4 col3\" >0.4811</td>\n",
       "      <td id=\"T_6802d_row4_col4\" class=\"data row4 col4\" >0.5128</td>\n",
       "      <td id=\"T_6802d_row4_col5\" class=\"data row4 col5\" >0.4951</td>\n",
       "      <td id=\"T_6802d_row4_col6\" class=\"data row4 col6\" >0.3216</td>\n",
       "      <td id=\"T_6802d_row4_col7\" class=\"data row4 col7\" >0.3225</td>\n",
       "      <td id=\"T_6802d_row4_col8\" class=\"data row4 col8\" >1.4120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row5\" class=\"row_heading level0 row5\" >rf</th>\n",
       "      <td id=\"T_6802d_row5_col0\" class=\"data row5 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_6802d_row5_col1\" class=\"data row5 col1\" >0.7583</td>\n",
       "      <td id=\"T_6802d_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row5_col3\" class=\"data row5 col3\" >0.4082</td>\n",
       "      <td id=\"T_6802d_row5_col4\" class=\"data row5 col4\" >0.5124</td>\n",
       "      <td id=\"T_6802d_row5_col5\" class=\"data row5 col5\" >0.4419</td>\n",
       "      <td id=\"T_6802d_row5_col6\" class=\"data row5 col6\" >0.2799</td>\n",
       "      <td id=\"T_6802d_row5_col7\" class=\"data row5 col7\" >0.2887</td>\n",
       "      <td id=\"T_6802d_row5_col8\" class=\"data row5 col8\" >3.6040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row6\" class=\"row_heading level0 row6\" >nb</th>\n",
       "      <td id=\"T_6802d_row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_6802d_row6_col1\" class=\"data row6 col1\" >0.5937</td>\n",
       "      <td id=\"T_6802d_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row6_col3\" class=\"data row6 col3\" >0.4068</td>\n",
       "      <td id=\"T_6802d_row6_col4\" class=\"data row6 col4\" >0.2306</td>\n",
       "      <td id=\"T_6802d_row6_col5\" class=\"data row6 col5\" >0.2421</td>\n",
       "      <td id=\"T_6802d_row6_col6\" class=\"data row6 col6\" >0.0556</td>\n",
       "      <td id=\"T_6802d_row6_col7\" class=\"data row6 col7\" >0.0678</td>\n",
       "      <td id=\"T_6802d_row6_col8\" class=\"data row6 col8\" >0.2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row7\" class=\"row_heading level0 row7\" >svm</th>\n",
       "      <td id=\"T_6802d_row7_col0\" class=\"data row7 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_6802d_row7_col1\" class=\"data row7 col1\" >0.7197</td>\n",
       "      <td id=\"T_6802d_row7_col2\" class=\"data row7 col2\" >0.7521</td>\n",
       "      <td id=\"T_6802d_row7_col3\" class=\"data row7 col3\" >0.3967</td>\n",
       "      <td id=\"T_6802d_row7_col4\" class=\"data row7 col4\" >0.4974</td>\n",
       "      <td id=\"T_6802d_row7_col5\" class=\"data row7 col5\" >0.3092</td>\n",
       "      <td id=\"T_6802d_row7_col6\" class=\"data row7 col6\" >0.1179</td>\n",
       "      <td id=\"T_6802d_row7_col7\" class=\"data row7 col7\" >0.1798</td>\n",
       "      <td id=\"T_6802d_row7_col8\" class=\"data row7 col8\" >1.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "      <td id=\"T_6802d_row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_6802d_row8_col1\" class=\"data row8 col1\" >0.5703</td>\n",
       "      <td id=\"T_6802d_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row8_col3\" class=\"data row8 col3\" >0.3842</td>\n",
       "      <td id=\"T_6802d_row8_col4\" class=\"data row8 col4\" >0.2722</td>\n",
       "      <td id=\"T_6802d_row8_col5\" class=\"data row8 col5\" >0.2978</td>\n",
       "      <td id=\"T_6802d_row8_col6\" class=\"data row8 col6\" >0.0379</td>\n",
       "      <td id=\"T_6802d_row8_col7\" class=\"data row8 col7\" >0.0296</td>\n",
       "      <td id=\"T_6802d_row8_col8\" class=\"data row8 col8\" >1.2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row9\" class=\"row_heading level0 row9\" >lda</th>\n",
       "      <td id=\"T_6802d_row9_col0\" class=\"data row9 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_6802d_row9_col1\" class=\"data row9 col1\" >0.7539</td>\n",
       "      <td id=\"T_6802d_row9_col2\" class=\"data row9 col2\" >0.8027</td>\n",
       "      <td id=\"T_6802d_row9_col3\" class=\"data row9 col3\" >0.3745</td>\n",
       "      <td id=\"T_6802d_row9_col4\" class=\"data row9 col4\" >0.4860</td>\n",
       "      <td id=\"T_6802d_row9_col5\" class=\"data row9 col5\" >0.3619</td>\n",
       "      <td id=\"T_6802d_row9_col6\" class=\"data row9 col6\" >0.2189</td>\n",
       "      <td id=\"T_6802d_row9_col7\" class=\"data row9 col7\" >0.2393</td>\n",
       "      <td id=\"T_6802d_row9_col8\" class=\"data row9 col8\" >0.6040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row10\" class=\"row_heading level0 row10\" >ridge</th>\n",
       "      <td id=\"T_6802d_row10_col0\" class=\"data row10 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_6802d_row10_col1\" class=\"data row10 col1\" >0.7546</td>\n",
       "      <td id=\"T_6802d_row10_col2\" class=\"data row10 col2\" >0.8025</td>\n",
       "      <td id=\"T_6802d_row10_col3\" class=\"data row10 col3\" >0.3574</td>\n",
       "      <td id=\"T_6802d_row10_col4\" class=\"data row10 col4\" >0.4402</td>\n",
       "      <td id=\"T_6802d_row10_col5\" class=\"data row10 col5\" >0.3474</td>\n",
       "      <td id=\"T_6802d_row10_col6\" class=\"data row10 col6\" >0.2091</td>\n",
       "      <td id=\"T_6802d_row10_col7\" class=\"data row10 col7\" >0.2258</td>\n",
       "      <td id=\"T_6802d_row10_col8\" class=\"data row10 col8\" >0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row11\" class=\"row_heading level0 row11\" >lr</th>\n",
       "      <td id=\"T_6802d_row11_col0\" class=\"data row11 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_6802d_row11_col1\" class=\"data row11 col1\" >0.7541</td>\n",
       "      <td id=\"T_6802d_row11_col2\" class=\"data row11 col2\" >0.8107</td>\n",
       "      <td id=\"T_6802d_row11_col3\" class=\"data row11 col3\" >0.2737</td>\n",
       "      <td id=\"T_6802d_row11_col4\" class=\"data row11 col4\" >0.4915</td>\n",
       "      <td id=\"T_6802d_row11_col5\" class=\"data row11 col5\" >0.3332</td>\n",
       "      <td id=\"T_6802d_row11_col6\" class=\"data row11 col6\" >0.1983</td>\n",
       "      <td id=\"T_6802d_row11_col7\" class=\"data row11 col7\" >0.2131</td>\n",
       "      <td id=\"T_6802d_row11_col8\" class=\"data row11 col8\" >2.3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row12\" class=\"row_heading level0 row12\" >et</th>\n",
       "      <td id=\"T_6802d_row12_col0\" class=\"data row12 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_6802d_row12_col1\" class=\"data row12 col1\" >0.7553</td>\n",
       "      <td id=\"T_6802d_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row12_col3\" class=\"data row12 col3\" >0.1546</td>\n",
       "      <td id=\"T_6802d_row12_col4\" class=\"data row12 col4\" >0.5332</td>\n",
       "      <td id=\"T_6802d_row12_col5\" class=\"data row12 col5\" >0.2027</td>\n",
       "      <td id=\"T_6802d_row12_col6\" class=\"data row12 col6\" >0.1266</td>\n",
       "      <td id=\"T_6802d_row12_col7\" class=\"data row12 col7\" >0.1504</td>\n",
       "      <td id=\"T_6802d_row12_col8\" class=\"data row12 col8\" >0.8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6802d_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_6802d_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_6802d_row13_col1\" class=\"data row13 col1\" >0.7546</td>\n",
       "      <td id=\"T_6802d_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row13_col3\" class=\"data row13 col3\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row13_col4\" class=\"data row13 col4\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row13_col5\" class=\"data row13 col5\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_6802d_row13_col8\" class=\"data row13 col8\" >0.1760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1109896d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models(sort='Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the best model for better recall\n",
    "# tuned_model = tune_model(best_model, optimize='Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pycaret Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target variable before anomaly detection setup\n",
    "train_df_anomaly = train_df.drop(columns=['LEAK_FLOW_FLAG'], errors='ignore')\n",
    "\n",
    "# Define features to use (exclude object & datetime columns)\n",
    "numeric_features = [col for col in train_df_anomaly.columns if train_df_anomaly[col].dtype in ['float64', 'int64']]\n",
    "ignore_features = ['FLIGHT_ID', 'UTC_TIME'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74041 entries, 0 to 74040\n",
      "Data columns (total 145 columns):\n",
      " #    Column                           Dtype         \n",
      "---   ------                           -----         \n",
      " 0    UTC_TIME                         datetime64[ns]\n",
      " 1    FUEL_USED_2                      float64       \n",
      " 2    FUEL_USED_3                      float64       \n",
      " 3    FUEL_USED_4                      float64       \n",
      " 4    FW_GEO_ALTITUDE                  float64       \n",
      " 5    VALUE_FOB                        float64       \n",
      " 6    VALUE_FUEL_QTY_CT                float64       \n",
      " 7    VALUE_FUEL_QTY_FT1               float64       \n",
      " 8    VALUE_FUEL_QTY_FT2               float64       \n",
      " 9    VALUE_FUEL_QTY_FT3               float64       \n",
      " 10   VALUE_FUEL_QTY_FT4               float64       \n",
      " 11   VALUE_FUEL_QTY_LXT               float64       \n",
      " 12   VALUE_FUEL_QTY_RXT               float64       \n",
      " 13   FUEL_USED_1                      float64       \n",
      " 14   FLIGHT_ID                        object        \n",
      " 15   START_FOB                        float64       \n",
      " 16   TOTAL_FUEL_USED                  float64       \n",
      " 17   EXPECTED_FOB                     float64       \n",
      " 18   FOB_DIFFERENCE                   float64       \n",
      " 19   FOB_CHANGE                       float64       \n",
      " 20   EXPECTED_FOB_CHANGE              float64       \n",
      " 21   FUEL_LEAK_RATE                   float64       \n",
      " 22   TOTAL_FUEL_LW                    float64       \n",
      " 23   TOTAL_FUEL_RW                    float64       \n",
      " 24   LW_RW_DIFF                       float64       \n",
      " 25   FUEL_IN_TANKS                    float64       \n",
      " 26   CALC_VALUE_FOB_DIFF              float64       \n",
      " 27   START_FOB_VS_FOB_FUELUSED        float64       \n",
      " 28   ALTITUDE_DIFF                    float64       \n",
      " 29   UTC_TIME_lag1                    datetime64[ns]\n",
      " 30   FUEL_USED_2_lag1                 float64       \n",
      " 31   FUEL_USED_3_lag1                 float64       \n",
      " 32   FUEL_USED_4_lag1                 float64       \n",
      " 33   FW_GEO_ALTITUDE_lag1             float64       \n",
      " 34   VALUE_FOB_lag1                   float64       \n",
      " 35   VALUE_FUEL_QTY_CT_lag1           float64       \n",
      " 36   VALUE_FUEL_QTY_FT1_lag1          float64       \n",
      " 37   VALUE_FUEL_QTY_FT2_lag1          float64       \n",
      " 38   VALUE_FUEL_QTY_FT3_lag1          float64       \n",
      " 39   VALUE_FUEL_QTY_FT4_lag1          float64       \n",
      " 40   VALUE_FUEL_QTY_LXT_lag1          float64       \n",
      " 41   VALUE_FUEL_QTY_RXT_lag1          float64       \n",
      " 42   FUEL_USED_1_lag1                 float64       \n",
      " 43   FLIGHT_ID_lag1                   object        \n",
      " 44   START_FOB_lag1                   float64       \n",
      " 45   TOTAL_FUEL_USED_lag1             float64       \n",
      " 46   EXPECTED_FOB_lag1                float64       \n",
      " 47   FOB_DIFFERENCE_lag1              float64       \n",
      " 48   FOB_CHANGE_lag1                  float64       \n",
      " 49   EXPECTED_FOB_CHANGE_lag1         float64       \n",
      " 50   FUEL_LEAK_RATE_lag1              float64       \n",
      " 51   TOTAL_FUEL_LW_lag1               float64       \n",
      " 52   TOTAL_FUEL_RW_lag1               float64       \n",
      " 53   LW_RW_DIFF_lag1                  float64       \n",
      " 54   FUEL_IN_TANKS_lag1               float64       \n",
      " 55   CALC_VALUE_FOB_DIFF_lag1         float64       \n",
      " 56   START_FOB_VS_FOB_FUELUSED_lag1   float64       \n",
      " 57   ALTITUDE_DIFF_lag1               float64       \n",
      " 58   UTC_TIME_lag3                    datetime64[ns]\n",
      " 59   FUEL_USED_2_lag3                 float64       \n",
      " 60   FUEL_USED_3_lag3                 float64       \n",
      " 61   FUEL_USED_4_lag3                 float64       \n",
      " 62   FW_GEO_ALTITUDE_lag3             float64       \n",
      " 63   VALUE_FOB_lag3                   float64       \n",
      " 64   VALUE_FUEL_QTY_CT_lag3           float64       \n",
      " 65   VALUE_FUEL_QTY_FT1_lag3          float64       \n",
      " 66   VALUE_FUEL_QTY_FT2_lag3          float64       \n",
      " 67   VALUE_FUEL_QTY_FT3_lag3          float64       \n",
      " 68   VALUE_FUEL_QTY_FT4_lag3          float64       \n",
      " 69   VALUE_FUEL_QTY_LXT_lag3          float64       \n",
      " 70   VALUE_FUEL_QTY_RXT_lag3          float64       \n",
      " 71   FUEL_USED_1_lag3                 float64       \n",
      " 72   FLIGHT_ID_lag3                   object        \n",
      " 73   START_FOB_lag3                   float64       \n",
      " 74   TOTAL_FUEL_USED_lag3             float64       \n",
      " 75   EXPECTED_FOB_lag3                float64       \n",
      " 76   FOB_DIFFERENCE_lag3              float64       \n",
      " 77   FOB_CHANGE_lag3                  float64       \n",
      " 78   EXPECTED_FOB_CHANGE_lag3         float64       \n",
      " 79   FUEL_LEAK_RATE_lag3              float64       \n",
      " 80   TOTAL_FUEL_LW_lag3               float64       \n",
      " 81   TOTAL_FUEL_RW_lag3               float64       \n",
      " 82   LW_RW_DIFF_lag3                  float64       \n",
      " 83   FUEL_IN_TANKS_lag3               float64       \n",
      " 84   CALC_VALUE_FOB_DIFF_lag3         float64       \n",
      " 85   START_FOB_VS_FOB_FUELUSED_lag3   float64       \n",
      " 86   ALTITUDE_DIFF_lag3               float64       \n",
      " 87   UTC_TIME_lag5                    datetime64[ns]\n",
      " 88   FUEL_USED_2_lag5                 float64       \n",
      " 89   FUEL_USED_3_lag5                 float64       \n",
      " 90   FUEL_USED_4_lag5                 float64       \n",
      " 91   FW_GEO_ALTITUDE_lag5             float64       \n",
      " 92   VALUE_FOB_lag5                   float64       \n",
      " 93   VALUE_FUEL_QTY_CT_lag5           float64       \n",
      " 94   VALUE_FUEL_QTY_FT1_lag5          float64       \n",
      " 95   VALUE_FUEL_QTY_FT2_lag5          float64       \n",
      " 96   VALUE_FUEL_QTY_FT3_lag5          float64       \n",
      " 97   VALUE_FUEL_QTY_FT4_lag5          float64       \n",
      " 98   VALUE_FUEL_QTY_LXT_lag5          float64       \n",
      " 99   VALUE_FUEL_QTY_RXT_lag5          float64       \n",
      " 100  FUEL_USED_1_lag5                 float64       \n",
      " 101  FLIGHT_ID_lag5                   object        \n",
      " 102  START_FOB_lag5                   float64       \n",
      " 103  TOTAL_FUEL_USED_lag5             float64       \n",
      " 104  EXPECTED_FOB_lag5                float64       \n",
      " 105  FOB_DIFFERENCE_lag5              float64       \n",
      " 106  FOB_CHANGE_lag5                  float64       \n",
      " 107  EXPECTED_FOB_CHANGE_lag5         float64       \n",
      " 108  FUEL_LEAK_RATE_lag5              float64       \n",
      " 109  TOTAL_FUEL_LW_lag5               float64       \n",
      " 110  TOTAL_FUEL_RW_lag5               float64       \n",
      " 111  LW_RW_DIFF_lag5                  float64       \n",
      " 112  FUEL_IN_TANKS_lag5               float64       \n",
      " 113  CALC_VALUE_FOB_DIFF_lag5         float64       \n",
      " 114  START_FOB_VS_FOB_FUELUSED_lag5   float64       \n",
      " 115  ALTITUDE_DIFF_lag5               float64       \n",
      " 116  UTC_TIME_lag10                   datetime64[ns]\n",
      " 117  FUEL_USED_2_lag10                float64       \n",
      " 118  FUEL_USED_3_lag10                float64       \n",
      " 119  FUEL_USED_4_lag10                float64       \n",
      " 120  FW_GEO_ALTITUDE_lag10            float64       \n",
      " 121  VALUE_FOB_lag10                  float64       \n",
      " 122  VALUE_FUEL_QTY_CT_lag10          float64       \n",
      " 123  VALUE_FUEL_QTY_FT1_lag10         float64       \n",
      " 124  VALUE_FUEL_QTY_FT2_lag10         float64       \n",
      " 125  VALUE_FUEL_QTY_FT3_lag10         float64       \n",
      " 126  VALUE_FUEL_QTY_FT4_lag10         float64       \n",
      " 127  VALUE_FUEL_QTY_LXT_lag10         float64       \n",
      " 128  VALUE_FUEL_QTY_RXT_lag10         float64       \n",
      " 129  FUEL_USED_1_lag10                float64       \n",
      " 130  FLIGHT_ID_lag10                  object        \n",
      " 131  START_FOB_lag10                  float64       \n",
      " 132  TOTAL_FUEL_USED_lag10            float64       \n",
      " 133  EXPECTED_FOB_lag10               float64       \n",
      " 134  FOB_DIFFERENCE_lag10             float64       \n",
      " 135  FOB_CHANGE_lag10                 float64       \n",
      " 136  EXPECTED_FOB_CHANGE_lag10        float64       \n",
      " 137  FUEL_LEAK_RATE_lag10             float64       \n",
      " 138  TOTAL_FUEL_LW_lag10              float64       \n",
      " 139  TOTAL_FUEL_RW_lag10              float64       \n",
      " 140  LW_RW_DIFF_lag10                 float64       \n",
      " 141  FUEL_IN_TANKS_lag10              float64       \n",
      " 142  CALC_VALUE_FOB_DIFF_lag10        float64       \n",
      " 143  START_FOB_VS_FOB_FUELUSED_lag10  float64       \n",
      " 144  ALTITUDE_DIFF_lag10              float64       \n",
      "dtypes: datetime64[ns](5), float64(135), object(5)\n",
      "memory usage: 81.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_anomaly.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALC_VALUE_FOB_DIFF_lag10       70\n",
      "CALC_VALUE_FOB_DIFF             71\n",
      "CALC_VALUE_FOB_DIFF_lag1        71\n",
      "CALC_VALUE_FOB_DIFF_lag5        71\n",
      "CALC_VALUE_FOB_DIFF_lag3        71\n",
      "                             ...  \n",
      "UTC_TIME_lag1                74041\n",
      "UTC_TIME_lag10               74041\n",
      "UTC_TIME_lag5                74041\n",
      "UTC_TIME_lag3                74041\n",
      "UTC_TIME                     74041\n",
      "Length: 145, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the number of unique values for each column in train_df\n",
    "unique_counts = train_df_anomaly.nunique().sort_values()\n",
    "\n",
    "# Print unique values per column\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.anomaly import setup, create_model, assign_model\n",
    "\n",
    "#PyCaret anomaly detection setup\n",
    "ano_setup = setup(\n",
    "    data=train_df_anomaly,  # Use modified dataset without LEAK_FLOW_FLAG\n",
    "    session_id=42,\n",
    "    numeric_features=numeric_features,  \n",
    "    ignore_features=ignore_features,  \n",
    "    normalize=True,  \n",
    "    transformation=True,  \n",
    "    remove_multicollinearity=True,  \n",
    "    multicollinearity_threshold=0.95,  \n",
    "    outliers_threshold=0.05,  \n",
    "    profile=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train multiple anomaly detection models\n",
    "iforest_model = create_model('iforest')  # Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lof_model = create_model('lof')  # Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign anomaly predictions for each model\n",
    "iforest_results = assign_model(iforest_model)\n",
    "lof_results = assign_model(lof_model)\n",
    "\n",
    "# Rename anomaly columns for clarity\n",
    "iforest_results.rename(columns={\"Anomaly\": \"Anomaly_iforest\"}, inplace=True)\n",
    "lof_results.rename(columns={\"Anomaly\": \"Anomaly_lof\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Merge anomaly results back into the original dataset\n",
    "df_eval = train_df[['FLIGHT_ID', 'LEAK_FLOW_FLAG']].copy()  # Ensure original dataset columns are available\n",
    "df_eval = df_eval.merge(iforest_results[['Anomaly_iforest']], left_index=True, right_index=True)\n",
    "df_eval = df_eval.merge(lof_results[['Anomaly_lof']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert anomalies (1 = Outlier) to match `LEAK_FLOW_FLAG` (1 = Leak)\n",
    "for col in ['Anomaly_iforest', 'Anomaly_lof']:\n",
    "    df_eval[col] = df_eval[col].astype(int)  # Ensure integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define a function to compute evaluation metrics\n",
    "def evaluate_model(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Compute metrics for each model\n",
    "metrics = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1-Score\": []\n",
    "}\n",
    "\n",
    "for model_name in ['Anomaly_iforest', 'Anomaly_lof']:\n",
    "    acc, prec, rec, f1 = evaluate_model(df_eval[model_name], df_eval[\"LEAK_FLOW_FLAG\"])\n",
    "    metrics[\"Model\"].append(model_name)\n",
    "    metrics[\"Accuracy\"].append(acc)\n",
    "    metrics[\"Precision\"].append(prec)\n",
    "    metrics[\"Recall\"].append(rec)\n",
    "    metrics[\"F1-Score\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anomaly_iforest</td>\n",
       "      <td>0.725044</td>\n",
       "      <td>0.254187</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.084622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anomaly_lof</td>\n",
       "      <td>0.726854</td>\n",
       "      <td>0.272285</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>0.090647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision    Recall  F1-Score\n",
       "0  Anomaly_iforest  0.725044   0.254187  0.050761  0.084622\n",
       "1      Anomaly_lof  0.726854   0.272285  0.054375  0.090647"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort flights by first recorded timestamp\n",
    "flight_start_times = df_balanced.groupby(\"FLIGHT_ID\")[\"UTC_TIME\"].min().sort_values()\n",
    "\n",
    "# Step 2: Define the split point (80% train, 20% test)\n",
    "split_index = int(len(flight_start_times) * 0.8)  # Get the 80% split point\n",
    "\n",
    "# Step 3: Assign the first 80% of flights to training, last 20% to testing\n",
    "train_flights = flight_start_times.index[:split_index]  # First 80% of flights\n",
    "test_flights = flight_start_times.index[split_index:]  # Last 20% of flights\n",
    "\n",
    "train_df = df_balanced[df_balanced[\"FLIGHT_ID\"].isin(train_flights)]\n",
    "test_df = df_balanced[df_balanced[\"FLIGHT_ID\"].isin(test_flights)]\n",
    "\n",
    "# Step 4: Reset index (ensures PyCaret compatibility)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features & target\n",
    "features = [col for col in train_df.columns if col not in ['FLIGHT_ID', 'UTC_TIME', 'LEAK_FLOW_FLAG']]\n",
    "target = \"LEAK_FLOW_FLAG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75861 entries, 0 to 75860\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   UTC_TIME                   75861 non-null  datetime64[ns]\n",
      " 1   FUEL_USED_2                75861 non-null  float64       \n",
      " 2   FUEL_USED_3                75861 non-null  float64       \n",
      " 3   FUEL_USED_4                75861 non-null  float64       \n",
      " 4   FW_GEO_ALTITUDE            75861 non-null  float64       \n",
      " 5   VALUE_FOB                  75861 non-null  float64       \n",
      " 6   VALUE_FUEL_QTY_CT          75861 non-null  float64       \n",
      " 7   VALUE_FUEL_QTY_FT1         75861 non-null  float64       \n",
      " 8   VALUE_FUEL_QTY_FT2         75861 non-null  float64       \n",
      " 9   VALUE_FUEL_QTY_FT3         75861 non-null  float64       \n",
      " 10  VALUE_FUEL_QTY_FT4         75861 non-null  float64       \n",
      " 11  VALUE_FUEL_QTY_LXT         75861 non-null  float64       \n",
      " 12  VALUE_FUEL_QTY_RXT         75861 non-null  float64       \n",
      " 13  FUEL_USED_1                75861 non-null  float64       \n",
      " 14  FLIGHT_ID                  75861 non-null  object        \n",
      " 15  START_FOB                  75861 non-null  float64       \n",
      " 16  TOTAL_FUEL_USED            75861 non-null  float64       \n",
      " 17  EXPECTED_FOB               75861 non-null  float64       \n",
      " 18  FOB_DIFFERENCE             75861 non-null  float64       \n",
      " 19  FOB_CHANGE                 75861 non-null  float64       \n",
      " 20  EXPECTED_FOB_CHANGE        75861 non-null  float64       \n",
      " 21  FUEL_LEAK_RATE             75861 non-null  float64       \n",
      " 22  TOTAL_FUEL_LW              75861 non-null  float64       \n",
      " 23  TOTAL_FUEL_RW              75861 non-null  float64       \n",
      " 24  LW_RW_DIFF                 75861 non-null  float64       \n",
      " 25  FUEL_IN_TANKS              75861 non-null  float64       \n",
      " 26  CALC_VALUE_FOB_DIFF        75861 non-null  float64       \n",
      " 27  START_FOB_VS_FOB_FUELUSED  75861 non-null  float64       \n",
      " 28  ALTITUDE_DIFF              75861 non-null  float64       \n",
      " 29  LEAK_FLOW_FLAG             75861 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
      "memory usage: 17.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Select numerical features only\n",
    "numerical_features = train_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Remove the target column (`LEAK_FLOW_FLAG`) from scaling\n",
    "numerical_features.remove(\"LEAK_FLOW_FLAG\")  \n",
    "\n",
    "# Normalize only numerical features (LSTMs perform better with scaled data)\n",
    "scaler = MinMaxScaler()\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time steps for LSTM (how many past steps to use for each prediction)\n",
    "time_steps = 10  # Use last 10 timesteps to predict next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Convert Data Into LSTM Format (3D: samples, time_steps, features)\n",
    "def create_lstm_sequences(df, features, target, time_steps=10):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Process each flight separately\n",
    "    for flight_id, flight_data in df.groupby(\"FLIGHT_ID\"):\n",
    "        flight_data = flight_data.sort_values(\"UTC_TIME\")  # Ensure correct order\n",
    "        feature_values = flight_data[features].values\n",
    "        target_values = flight_data[target].values\n",
    "\n",
    "        # Create sequences\n",
    "        for i in range(time_steps, len(flight_data)):\n",
    "            X.append(feature_values[i - time_steps:i])  # Last `time_steps` for each row\n",
    "            y.append(target_values[i])  # Next step's target value\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to training & testing sets\n",
    "X_train, y_train = create_lstm_sequences(train_df, numerical_features, \"LEAK_FLOW_FLAG\", time_steps=10)\n",
    "X_test, y_test = create_lstm_sequences(test_df, numerical_features, \"LEAK_FLOW_FLAG\", time_steps=10)\n",
    "\n",
    "# Convert target to categorical (for binary classification)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (74041, 10, 27) (74041, 2)\n",
      "Test Shape: (30102, 10, 27) (30102, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print Final Shape\n",
    "print(\"Train Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test Shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation=\"softmax\")  # Binary classification (leak=1, no leak=0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the f1 score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Custom Precision\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    predicted_positives = K.sum(K.round(y_pred))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "# Custom Recall\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    possible_positives = K.sum(K.round(y_true))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "# Custom F1 Score\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * ((prec * rec) / (prec + rec + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\", \n",
    "        precision, \n",
    "        recall, \n",
    "        f1_score, \n",
    "        tf.keras.metrics.AUC(name=\"auc\")  # Built-in AUC-ROC\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m23,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,034</span> (140.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,034\u001b[0m (140.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,034</span> (140.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,034\u001b[0m (140.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7516 - auc: 0.8735 - f1_score: 0.7516 - loss: 0.3797 - precision: 0.7516 - recall: 0.7516 - val_accuracy: 0.4698 - val_auc: 0.5630 - val_f1_score: 0.4699 - val_loss: 0.6679 - val_precision: 0.4699 - val_recall: 0.4699\n",
      "Epoch 2/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7490 - auc: 0.8715 - f1_score: 0.7490 - loss: 0.3805 - precision: 0.7490 - recall: 0.7490 - val_accuracy: 0.3106 - val_auc: 0.4136 - val_f1_score: 0.3107 - val_loss: 0.7376 - val_precision: 0.3107 - val_recall: 0.3107\n",
      "Epoch 3/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7532 - auc: 0.8756 - f1_score: 0.7532 - loss: 0.3709 - precision: 0.7532 - recall: 0.7532 - val_accuracy: 0.3103 - val_auc: 0.3830 - val_f1_score: 0.3104 - val_loss: 0.7210 - val_precision: 0.3104 - val_recall: 0.3104\n",
      "Epoch 4/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7499 - auc: 0.8735 - f1_score: 0.7499 - loss: 0.3705 - precision: 0.7499 - recall: 0.7499 - val_accuracy: 0.3726 - val_auc: 0.3636 - val_f1_score: 0.3726 - val_loss: 0.8502 - val_precision: 0.3726 - val_recall: 0.3726\n",
      "Epoch 5/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7512 - auc: 0.8739 - f1_score: 0.7512 - loss: 0.3702 - precision: 0.7512 - recall: 0.7512 - val_accuracy: 0.4295 - val_auc: 0.4785 - val_f1_score: 0.4295 - val_loss: 0.7885 - val_precision: 0.4295 - val_recall: 0.4295\n",
      "Epoch 6/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7509 - auc: 0.8743 - f1_score: 0.7509 - loss: 0.3652 - precision: 0.7509 - recall: 0.7509 - val_accuracy: 0.5503 - val_auc: 0.6348 - val_f1_score: 0.5503 - val_loss: 0.6418 - val_precision: 0.5503 - val_recall: 0.5503\n",
      "Epoch 7/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7523 - auc: 0.8765 - f1_score: 0.7523 - loss: 0.3670 - precision: 0.7523 - recall: 0.7523 - val_accuracy: 0.5819 - val_auc: 0.6882 - val_f1_score: 0.5819 - val_loss: 0.5571 - val_precision: 0.5819 - val_recall: 0.5819\n",
      "Epoch 8/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7551 - auc: 0.8780 - f1_score: 0.7551 - loss: 0.3627 - precision: 0.7551 - recall: 0.7551 - val_accuracy: 0.7908 - val_auc: 0.8287 - val_f1_score: 0.7907 - val_loss: 0.5487 - val_precision: 0.7907 - val_recall: 0.7907\n",
      "Epoch 9/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7550 - auc: 0.8779 - f1_score: 0.7550 - loss: 0.3640 - precision: 0.7550 - recall: 0.7550 - val_accuracy: 0.6857 - val_auc: 0.7056 - val_f1_score: 0.6857 - val_loss: 0.6279 - val_precision: 0.6857 - val_recall: 0.6857\n",
      "Epoch 10/10\n",
      "\u001b[1m2314/2314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7519 - auc: 0.8749 - f1_score: 0.7519 - loss: 0.3650 - precision: 0.7519 - recall: 0.7519 - val_accuracy: 0.6117 - val_auc: 0.6880 - val_f1_score: 0.6116 - val_loss: 0.6048 - val_precision: 0.6116 - val_recall: 0.6116\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM Model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save Model \n",
    "model.save(\"lstm_fuel_leak_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m941/941\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "LSTM Model - Accuracy: 0.4766, Precision: 0.2489, Recall: 0.7788, F1-Score: 0.3773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Get Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
    "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding back to labels\n",
    "\n",
    "# Compute Classification Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(f\"LSTM Model - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=np.unique(np.argmax(y_train, axis=1)),  # Get class labels from one-hot encoding\n",
    "    y=np.argmax(y_train, axis=1)  # Convert one-hot encoding back to labels\n",
    ")\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define Deeper LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation=\"softmax\")  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with Adam Optimizer & Learning Rate Adjustment\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Reduce learning rate\n",
    "    metrics=[\"accuracy\", precision, recall, f1_score, tf.keras.metrics.AUC(name=\"auc\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.6267 - auc: 0.6989 - f1_score: 0.6267 - loss: 0.5861 - precision: 0.6267 - recall: 0.6267 - val_accuracy: 0.4154 - val_auc: 0.4631 - val_f1_score: 0.4155 - val_loss: 0.9042 - val_precision: 0.4155 - val_recall: 0.4155\n",
      "Epoch 2/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7237 - auc: 0.8451 - f1_score: 0.7237 - loss: 0.4313 - precision: 0.7237 - recall: 0.7237 - val_accuracy: 0.2880 - val_auc: 0.3133 - val_f1_score: 0.2884 - val_loss: 1.0577 - val_precision: 0.2884 - val_recall: 0.2884\n",
      "Epoch 3/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7200 - auc: 0.8430 - f1_score: 0.7200 - loss: 0.4325 - precision: 0.7200 - recall: 0.7200 - val_accuracy: 0.2642 - val_auc: 0.3024 - val_f1_score: 0.2646 - val_loss: 1.0528 - val_precision: 0.2646 - val_recall: 0.2646\n",
      "Epoch 4/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7339 - auc: 0.8569 - f1_score: 0.7339 - loss: 0.4155 - precision: 0.7339 - recall: 0.7339 - val_accuracy: 0.2461 - val_auc: 0.2576 - val_f1_score: 0.2465 - val_loss: 1.1784 - val_precision: 0.2465 - val_recall: 0.2465\n",
      "Epoch 5/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7292 - auc: 0.8549 - f1_score: 0.7292 - loss: 0.4164 - precision: 0.7292 - recall: 0.7292 - val_accuracy: 0.2450 - val_auc: 0.2454 - val_f1_score: 0.2454 - val_loss: 1.1413 - val_precision: 0.2454 - val_recall: 0.2454\n",
      "Epoch 6/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7315 - auc: 0.8543 - f1_score: 0.7315 - loss: 0.4200 - precision: 0.7315 - recall: 0.7315 - val_accuracy: 0.2344 - val_auc: 0.2025 - val_f1_score: 0.2348 - val_loss: 1.1192 - val_precision: 0.2348 - val_recall: 0.2348\n",
      "Epoch 7/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7322 - auc: 0.8544 - f1_score: 0.7322 - loss: 0.4180 - precision: 0.7322 - recall: 0.7322 - val_accuracy: 0.2409 - val_auc: 0.2398 - val_f1_score: 0.2414 - val_loss: 1.1658 - val_precision: 0.2414 - val_recall: 0.2414\n",
      "Epoch 8/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7326 - auc: 0.8566 - f1_score: 0.7326 - loss: 0.4112 - precision: 0.7326 - recall: 0.7326 - val_accuracy: 0.2365 - val_auc: 0.2312 - val_f1_score: 0.2369 - val_loss: 1.1748 - val_precision: 0.2369 - val_recall: 0.2369\n",
      "Epoch 9/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7325 - auc: 0.8565 - f1_score: 0.7325 - loss: 0.4107 - precision: 0.7325 - recall: 0.7325 - val_accuracy: 0.2367 - val_auc: 0.2225 - val_f1_score: 0.2371 - val_loss: 1.1171 - val_precision: 0.2371 - val_recall: 0.2371\n",
      "Epoch 10/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7302 - auc: 0.8555 - f1_score: 0.7302 - loss: 0.4096 - precision: 0.7302 - recall: 0.7302 - val_accuracy: 0.2281 - val_auc: 0.2005 - val_f1_score: 0.2286 - val_loss: 1.1586 - val_precision: 0.2286 - val_recall: 0.2286\n",
      "Epoch 11/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7379 - auc: 0.8623 - f1_score: 0.7379 - loss: 0.4018 - precision: 0.7379 - recall: 0.7379 - val_accuracy: 0.2474 - val_auc: 0.2401 - val_f1_score: 0.2478 - val_loss: 1.1399 - val_precision: 0.2478 - val_recall: 0.2478\n",
      "Epoch 12/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7337 - auc: 0.8592 - f1_score: 0.7337 - loss: 0.4037 - precision: 0.7337 - recall: 0.7337 - val_accuracy: 0.2061 - val_auc: 0.2127 - val_f1_score: 0.2066 - val_loss: 1.1267 - val_precision: 0.2066 - val_recall: 0.2066\n",
      "Epoch 13/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7369 - auc: 0.8614 - f1_score: 0.7369 - loss: 0.4010 - precision: 0.7369 - recall: 0.7369 - val_accuracy: 0.2035 - val_auc: 0.2098 - val_f1_score: 0.2040 - val_loss: 1.1332 - val_precision: 0.2040 - val_recall: 0.2040\n",
      "Epoch 14/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7336 - auc: 0.8599 - f1_score: 0.7336 - loss: 0.4039 - precision: 0.7336 - recall: 0.7336 - val_accuracy: 0.2076 - val_auc: 0.2103 - val_f1_score: 0.2081 - val_loss: 1.1080 - val_precision: 0.2081 - val_recall: 0.2081\n",
      "Epoch 15/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7292 - auc: 0.8546 - f1_score: 0.7292 - loss: 0.4085 - precision: 0.7292 - recall: 0.7292 - val_accuracy: 0.2668 - val_auc: 0.3427 - val_f1_score: 0.2672 - val_loss: 1.1405 - val_precision: 0.2672 - val_recall: 0.2672\n",
      "Epoch 16/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7362 - auc: 0.8615 - f1_score: 0.7362 - loss: 0.4006 - precision: 0.7362 - recall: 0.7362 - val_accuracy: 0.2127 - val_auc: 0.1941 - val_f1_score: 0.2132 - val_loss: 1.1773 - val_precision: 0.2132 - val_recall: 0.2132\n",
      "Epoch 17/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.7390 - auc: 0.8640 - f1_score: 0.7390 - loss: 0.3966 - precision: 0.7390 - recall: 0.7390 - val_accuracy: 0.2244 - val_auc: 0.2358 - val_f1_score: 0.2249 - val_loss: 1.1512 - val_precision: 0.2249 - val_recall: 0.2249\n",
      "Epoch 18/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.7360 - auc: 0.8612 - f1_score: 0.7360 - loss: 0.4009 - precision: 0.7360 - recall: 0.7360 - val_accuracy: 0.2511 - val_auc: 0.2526 - val_f1_score: 0.2515 - val_loss: 1.1199 - val_precision: 0.2515 - val_recall: 0.2515\n",
      "Epoch 19/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7391 - auc: 0.8651 - f1_score: 0.7391 - loss: 0.3962 - precision: 0.7391 - recall: 0.7391 - val_accuracy: 0.2152 - val_auc: 0.2230 - val_f1_score: 0.2157 - val_loss: 1.1881 - val_precision: 0.2157 - val_recall: 0.2157\n",
      "Epoch 20/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7374 - auc: 0.8631 - f1_score: 0.7374 - loss: 0.3969 - precision: 0.7374 - recall: 0.7374 - val_accuracy: 0.2558 - val_auc: 0.2767 - val_f1_score: 0.2562 - val_loss: 1.0746 - val_precision: 0.2562 - val_recall: 0.2562\n",
      "Epoch 21/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7393 - auc: 0.8636 - f1_score: 0.7393 - loss: 0.3963 - precision: 0.7393 - recall: 0.7393 - val_accuracy: 0.2233 - val_auc: 0.2470 - val_f1_score: 0.2238 - val_loss: 1.1451 - val_precision: 0.2238 - val_recall: 0.2238\n",
      "Epoch 22/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7378 - auc: 0.8634 - f1_score: 0.7378 - loss: 0.3975 - precision: 0.7378 - recall: 0.7378 - val_accuracy: 0.4798 - val_auc: 0.6340 - val_f1_score: 0.4799 - val_loss: 0.8513 - val_precision: 0.4799 - val_recall: 0.4799\n",
      "Epoch 23/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7400 - auc: 0.8648 - f1_score: 0.7400 - loss: 0.3956 - precision: 0.7400 - recall: 0.7400 - val_accuracy: 0.2556 - val_auc: 0.3001 - val_f1_score: 0.2560 - val_loss: 1.0856 - val_precision: 0.2560 - val_recall: 0.2560\n",
      "Epoch 24/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.7383 - auc: 0.8648 - f1_score: 0.7383 - loss: 0.3955 - precision: 0.7383 - recall: 0.7383 - val_accuracy: 0.2464 - val_auc: 0.2853 - val_f1_score: 0.2468 - val_loss: 1.0809 - val_precision: 0.2468 - val_recall: 0.2468\n",
      "Epoch 25/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7333 - auc: 0.8604 - f1_score: 0.7333 - loss: 0.4013 - precision: 0.7333 - recall: 0.7333 - val_accuracy: 0.3403 - val_auc: 0.4423 - val_f1_score: 0.3406 - val_loss: 1.0860 - val_precision: 0.3406 - val_recall: 0.3406\n",
      "Epoch 26/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7397 - auc: 0.8652 - f1_score: 0.7397 - loss: 0.3934 - precision: 0.7397 - recall: 0.7397 - val_accuracy: 0.2614 - val_auc: 0.3159 - val_f1_score: 0.2618 - val_loss: 1.1410 - val_precision: 0.2618 - val_recall: 0.2618\n",
      "Epoch 27/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7414 - auc: 0.8670 - f1_score: 0.7414 - loss: 0.3937 - precision: 0.7414 - recall: 0.7414 - val_accuracy: 0.2610 - val_auc: 0.3249 - val_f1_score: 0.2614 - val_loss: 1.0315 - val_precision: 0.2614 - val_recall: 0.2614\n",
      "Epoch 28/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7419 - auc: 0.8665 - f1_score: 0.7419 - loss: 0.3926 - precision: 0.7419 - recall: 0.7419 - val_accuracy: 0.3236 - val_auc: 0.3424 - val_f1_score: 0.3239 - val_loss: 0.9810 - val_precision: 0.3239 - val_recall: 0.3239\n",
      "Epoch 29/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7408 - auc: 0.8648 - f1_score: 0.7408 - loss: 0.3950 - precision: 0.7408 - recall: 0.7408 - val_accuracy: 0.2906 - val_auc: 0.3591 - val_f1_score: 0.2909 - val_loss: 1.0740 - val_precision: 0.2909 - val_recall: 0.2909\n",
      "Epoch 30/30\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7378 - auc: 0.8633 - f1_score: 0.7378 - loss: 0.3978 - precision: 0.7378 - recall: 0.7378 - val_accuracy: 0.2814 - val_auc: 0.3436 - val_f1_score: 0.2818 - val_loss: 1.0846 - val_precision: 0.2818 - val_recall: 0.2818\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=30,  # Train longer for better learning\n",
    "    batch_size=64,  # Larger batch sizes for stability\n",
    "    validation_data=(X_test, y_test), \n",
    "    class_weight=class_weight_dict  # Use class weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save Model (Optional)\n",
    "model.save(\"lstm_fuel_leak_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m941/941\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "LSTM Model - Accuracy: 0.2814, Precision: 0.2064, Recall: 0.8895, F1-Score: 0.3351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Get Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
    "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding back to labels\n",
    "\n",
    "# Compute Classification Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(f\"LSTM Model - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m941/941\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "LSTM Model - Accuracy: 0.2814, Precision: 0.2064, Recall: 0.8895, F1-Score: 0.3351, ROC-AUC: 0.5078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Get Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
    "y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoding back to labels\n",
    "\n",
    "# Compute Classification Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_pred)  # Added ROC-AUC\n",
    "\n",
    "# Print Results\n",
    "print(f\"LSTM Model - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
